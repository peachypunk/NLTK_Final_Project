{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presidential Candidate Analysis#\n",
    "\n",
    "For our final project, Zoe, Nene and Angela used the NLTK package to perform sentiment analysis of a series of transcripts of speeches delivered by the 2016 presidential candidates, Hillary Clinton and Donald Trump. \n",
    "\n",
    "The ANEW dictionary was used (more details provided under its own subsection below) to generate sentiment values for each word in their dictionary. Values were provided for three domains: valence, arousal, and dominance. All three values are scored from 1 to 9 and the scores for each word were used as subsequent weights. \n",
    "\n",
    "Prior to performing our analysis, we hypothesized that: \n",
    "\n",
    "-Clinton would have a more positive average valence score across all her speeches compared to Trump\n",
    "\n",
    "-Trump would have a higher arousal score than Clinton\n",
    "\n",
    "-Trump would have a higher dominance score than Clinton\n",
    "\n",
    "The text used for our analysis can be found here: https://github.com/peachypunk/NLTK_Final_Project/tree/master/Clinton-Trump-Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/Z/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Import the packages\n",
    "import nltk\n",
    "import nltk.corpus\n",
    "import pickle\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "nltk.download(\"stopwords\") #Import stopwords and punctuation from NLTK\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and form corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trump_corpus = nltk.corpus.PlaintextCorpusReader('Clinton-Trump-Corpus/Trump/','Trump_.*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clinton_corpus = nltk.corpus.PlaintextCorpusReader('Clinton-Trump-Corpus/Clinton/','Clinton_.*.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we are doing conversions between the \"raw\" text, the tokenized \"words\", and the plain \"text\" type. This will be used later because some functions require a certain object type, and some methods are only callable from certain object types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trump_raw = trump_corpus.raw()\n",
    "trump_words = trump_corpus.words()\n",
    "trump_text = nltk.Text(trump_words)\n",
    "\n",
    "clinton_raw = clinton_corpus.raw()\n",
    "clinton_words = clinton_corpus.words()\n",
    "clinton_text = nltk.Text(clinton_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up the data\n",
    "Get rid of applause, stop words, anything between < >, punctuation \" -- . , '\n",
    "Write a for loop to clean up all the data \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this is a function that filters out the stopwords, punctuation, and audience directions in a given corpus\n",
    "\n",
    "def clean_up_data(x):\n",
    "    filtered_for_punctuation = x\n",
    "    filtered_for_punctuation = filtered_for_punctuation.lower() #convert all words to lowercase\n",
    "    filtered_for_punctuation = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", filtered_for_punctuation) #remove parentheses\n",
    "    filtered_for_punctuation = re.sub(\"[\\<\\[].*?[\\>\\]]\", \"\", filtered_for_punctuation) #remove carrots    for punc in punctuation:\n",
    "    for punc in punctuation:\n",
    "        filtered_for_punctuation = filtered_for_punctuation.replace(punc, \"\") #remove punctuation\n",
    "    filtered_for_punctuation = nltk.wordpunct_tokenize(filtered_for_punctuation) #tokenize text\n",
    "    filtered_for_punctuation = [word for word in filtered_for_punctuation if word.lower() not in stopwords.words('english')] #remove stopwords\n",
    "        #note that stopwords include words like very and against \n",
    "    return filtered_for_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean_clinton    [thank, thank, much, thank, thank, much, thank...\n",
       "clean_trump      [thank, much, amazing, convention, one, best, ...\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean up both corpora using the custom function from above\n",
    "clean_trump = clean_up_data(trump_raw)\n",
    "clean_clinton = clean_up_data(clinton_raw)\n",
    "\n",
    "#join the corpora together while keeping them as separate entities as part of one \n",
    "#larger corpus umbrella\n",
    "collected_corpora_df = {'clean_clinton' : clean_clinton, 'clean_trump' : clean_trump}\n",
    "pd.Series(collected_corpora_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the \"ANEW\" sentiment dictionary\n",
    "\"ANEW\" stands for \"Affective Norms for English Words\".\n",
    "It is a list of 2476 words that have been normed for ratings on 3 affective dimensions: Valence, Arousal, and Dominance. The rating is on a Likert Scale ranging from 1 to 9, with a higher rating indicating higher valence, arousal, or dominance, respectively. Each word has a mean valence, arousal, and dominance rating, as well as the associated standard deviations for each mean.\n",
    "\"Wdnum\" is presumably the \"word number\" or an arbitrary number label assigned to each word. We won't be using this variable in our sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Wdnum</th>\n",
       "      <th>ValMn</th>\n",
       "      <th>ValSD</th>\n",
       "      <th>AroMn</th>\n",
       "      <th>AroSD</th>\n",
       "      <th>DomMn</th>\n",
       "      <th>DomSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abduction</td>\n",
       "      <td>621</td>\n",
       "      <td>2.76</td>\n",
       "      <td>2.06</td>\n",
       "      <td>5.53</td>\n",
       "      <td>2.43</td>\n",
       "      <td>3.49</td>\n",
       "      <td>2.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>able</td>\n",
       "      <td>1041</td>\n",
       "      <td>6.74</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.30</td>\n",
       "      <td>2.17</td>\n",
       "      <td>6.83</td>\n",
       "      <td>2.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abortion</td>\n",
       "      <td>622</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.30</td>\n",
       "      <td>5.39</td>\n",
       "      <td>2.80</td>\n",
       "      <td>4.59</td>\n",
       "      <td>2.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>absent</td>\n",
       "      <td>1042</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.72</td>\n",
       "      <td>4.73</td>\n",
       "      <td>1.76</td>\n",
       "      <td>4.35</td>\n",
       "      <td>1.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>absurd</td>\n",
       "      <td>623</td>\n",
       "      <td>4.26</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.36</td>\n",
       "      <td>2.20</td>\n",
       "      <td>4.73</td>\n",
       "      <td>1.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word  Wdnum  ValMn  ValSD  AroMn  AroSD  DomMn  DomSD\n",
       "0  abduction    621   2.76   2.06   5.53   2.43   3.49   2.38\n",
       "1       able   1041   6.74   2.00   4.30   2.17   6.83   2.04\n",
       "2   abortion    622   3.50   2.30   5.39   2.80   4.59   2.54\n",
       "3     absent   1042   3.69   1.72   4.73   1.76   4.35   1.87\n",
       "4     absurd    623   4.26   1.82   4.36   2.20   4.73   1.72"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load ANEW sentiment dictionary\n",
    "anew_df = pd.read_csv('https://github.com/peachypunk/NLTK_Final_Project/raw/master/ANEW2010_CSV.csv')\n",
    "anew_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we're taking all the words in anew_df and storing it in a list called \"wordlist\". This will make it easier to do word counting later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#take the \"Word\" column from the anew_df and convert it into a list called \"wordlist\"\n",
    "wordlist = anew_df[\"Word\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform word counting\n",
    "To perform sentiment analysis based on the words from ANEW, we will first perform a word count of how many times each ANEW word appears in the Trump corpus and Clinton corpus, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialize an empty array for the summed word counts for each w in wordlist\n",
    "#these will be summed across all corpora in the larger corpus as well\n",
    "wordfreq_corpus = [] \n",
    "\n",
    "#make an empty matrix that's the size of the ANEX words and two corpora \n",
    "matrix = np.zeros((len(collected_corpora_df), len(wordlist)))\n",
    "for i, cid in enumerate(collected_corpora_df): #for each corpus in the list of corpora\n",
    "    this_corpus_words = collected_corpora_df[(cid)]\n",
    "    for j, w in enumerate(wordlist): #for each word in the ANEW wordlist...\n",
    "        count = this_corpus_words.count(w) #count how many times each word (w) occurs in the wordlist for each corpus\n",
    "        matrix[i,j] = count\n",
    "        \n",
    "df = pd.DataFrame(matrix)\n",
    "df.columns = wordlist\n",
    "df.index = collected_corpora_df.keys()\n",
    "#print(df)\n",
    "\n",
    "#optional: print the output to a csv file. just change the \"path_or_buf\" part to be where you\n",
    "#want to save the file\n",
    "#df.to_csv(path_or_buf='/Users/angelanazarian/nltk_output.csv', sep=',', header=True, index=True, line_terminator='\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We successfully performed word counting: the above output contains the count for each ANEW word in the Clinton corpus and Trump corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform calculation of weighted MEANS for valence, arousal, and dominance (for each word)\n",
    "Using the word counts we obtained above, we will now calculate each weighted means separately for each affective dimension (valenc, arousal, dominance) and for each corpus (Trump, Clinton).\n",
    "\n",
    "For each word \"w\" in the ANEW word list: Weighted mean = sum of [count of \"w\" in the corpus x mean affective rating of \"w\" from ANEW], for each corpus\n",
    "\n",
    "Below, we are converting the word count dataframe \"df\" into a transposed dataframe with sensible row indices and column labels. Essentially, we're converting \"df\" from wide format into long format to make it easier to calculate the weighted means. The resulting dataframe is called \"df_long\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>clinton_WC</th>\n",
       "      <th>trump_WC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abduction</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>able</td>\n",
       "      <td>66.0</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abortion</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>absent</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>absurd</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abundance</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abuse</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>accept</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>acceptance</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>access</td>\n",
       "      <td>22.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>accident</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>accord</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>accost</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>accuse</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ace</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ache</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>achievement</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>acre</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>action</td>\n",
       "      <td>17.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>activate</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>actor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ad</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>adapt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>addict</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>addicted</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>adhere</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>adjust</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>admire</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>admired</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>admit</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2446</th>\n",
       "      <td>wishful</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>wit</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2448</th>\n",
       "      <td>wolf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2449</th>\n",
       "      <td>woman</td>\n",
       "      <td>30.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2450</th>\n",
       "      <td>wonder</td>\n",
       "      <td>12.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2451</th>\n",
       "      <td>wood</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>wool</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2453</th>\n",
       "      <td>work</td>\n",
       "      <td>341.0</td>\n",
       "      <td>381.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454</th>\n",
       "      <td>worker</td>\n",
       "      <td>11.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>world</td>\n",
       "      <td>130.0</td>\n",
       "      <td>552.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2456</th>\n",
       "      <td>worry</td>\n",
       "      <td>5.0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2457</th>\n",
       "      <td>worth</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2458</th>\n",
       "      <td>wounds</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2459</th>\n",
       "      <td>wrath</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2460</th>\n",
       "      <td>wreath</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2461</th>\n",
       "      <td>wring</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2462</th>\n",
       "      <td>writer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2463</th>\n",
       "      <td>wrong</td>\n",
       "      <td>39.0</td>\n",
       "      <td>113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2464</th>\n",
       "      <td>yacht</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2465</th>\n",
       "      <td>year</td>\n",
       "      <td>71.0</td>\n",
       "      <td>221.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>yellow</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2467</th>\n",
       "      <td>yelp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>yolk</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>young</td>\n",
       "      <td>135.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>youth</td>\n",
       "      <td>3.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>zeal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>zealous</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>zest</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>zipper</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>zoom</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2476 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word  clinton_WC  trump_WC\n",
       "0       abduction         0.0       0.0\n",
       "1            able        66.0      96.0\n",
       "2        abortion         0.0       0.0\n",
       "3          absent         0.0       0.0\n",
       "4          absurd         1.0       0.0\n",
       "5       abundance         0.0       0.0\n",
       "6           abuse         4.0       3.0\n",
       "7          accept         7.0      13.0\n",
       "8      acceptance         1.0       1.0\n",
       "9          access        22.0      34.0\n",
       "10       accident         2.0       3.0\n",
       "11         accord         0.0       0.0\n",
       "12         accost         0.0       0.0\n",
       "13         accuse         0.0       2.0\n",
       "14            ace         0.0       0.0\n",
       "15           ache         0.0       0.0\n",
       "16    achievement         3.0       2.0\n",
       "17           acre         0.0       0.0\n",
       "18         action        17.0      26.0\n",
       "19       activate         0.0       0.0\n",
       "20          actor         0.0       2.0\n",
       "21             ad         4.0      16.0\n",
       "22          adapt         0.0       1.0\n",
       "23         addict         0.0       0.0\n",
       "24       addicted         0.0      12.0\n",
       "25         adhere         0.0       1.0\n",
       "26         adjust         0.0       1.0\n",
       "27         admire         5.0       0.0\n",
       "28        admired         3.0       0.0\n",
       "29          admit         5.0      20.0\n",
       "...           ...         ...       ...\n",
       "2446      wishful         0.0       0.0\n",
       "2447          wit         0.0       0.0\n",
       "2448         wolf         0.0       4.0\n",
       "2449        woman        30.0     101.0\n",
       "2450       wonder        12.0      55.0\n",
       "2451         wood         0.0       0.0\n",
       "2452         wool         0.0       0.0\n",
       "2453         work       341.0     381.0\n",
       "2454       worker        11.0      36.0\n",
       "2455        world       130.0     552.0\n",
       "2456        worry         5.0      76.0\n",
       "2457        worth        15.0       8.0\n",
       "2458       wounds         1.0       1.0\n",
       "2459        wrath         0.0       0.0\n",
       "2460       wreath         0.0       0.0\n",
       "2461        wring         0.0       0.0\n",
       "2462       writer         0.0       4.0\n",
       "2463        wrong        39.0     113.0\n",
       "2464        yacht         0.0       0.0\n",
       "2465         year        71.0     221.0\n",
       "2466       yellow         0.0       5.0\n",
       "2467         yelp         0.0       0.0\n",
       "2468         yolk         0.0       0.0\n",
       "2469        young       135.0      62.0\n",
       "2470        youth         3.0      81.0\n",
       "2471         zeal         0.0       0.0\n",
       "2472      zealous         0.0       0.0\n",
       "2473         zest         0.0       0.0\n",
       "2474       zipper         0.0       0.0\n",
       "2475         zoom         0.0       0.0\n",
       "\n",
       "[2476 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wide = df.copy() #make a copy of df and calling it \"df_wide\"\n",
    "df_long = df_wide.transpose() #transpose \"df_wide\" into \"df_long\" format\n",
    "df_long.reset_index(level=0, inplace=True) #converting the ANEW word indices into numeric indices\n",
    "df_long.columns = ['Word', 'clinton_WC', 'trump_WC'] #renaming columns (WC = word count)\n",
    "df_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>ValMn</th>\n",
       "      <th>AroMn</th>\n",
       "      <th>DomMn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abduction</td>\n",
       "      <td>2.76</td>\n",
       "      <td>5.53</td>\n",
       "      <td>3.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>able</td>\n",
       "      <td>6.74</td>\n",
       "      <td>4.30</td>\n",
       "      <td>6.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abortion</td>\n",
       "      <td>3.50</td>\n",
       "      <td>5.39</td>\n",
       "      <td>4.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>absent</td>\n",
       "      <td>3.69</td>\n",
       "      <td>4.73</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>absurd</td>\n",
       "      <td>4.26</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abundance</td>\n",
       "      <td>6.59</td>\n",
       "      <td>5.51</td>\n",
       "      <td>5.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abuse</td>\n",
       "      <td>1.80</td>\n",
       "      <td>6.83</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>accept</td>\n",
       "      <td>6.80</td>\n",
       "      <td>5.53</td>\n",
       "      <td>5.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>acceptance</td>\n",
       "      <td>7.98</td>\n",
       "      <td>5.40</td>\n",
       "      <td>6.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>access</td>\n",
       "      <td>6.14</td>\n",
       "      <td>5.07</td>\n",
       "      <td>6.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>accident</td>\n",
       "      <td>2.05</td>\n",
       "      <td>6.26</td>\n",
       "      <td>3.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>accord</td>\n",
       "      <td>5.53</td>\n",
       "      <td>4.24</td>\n",
       "      <td>5.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>accost</td>\n",
       "      <td>4.28</td>\n",
       "      <td>5.24</td>\n",
       "      <td>4.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>accuse</td>\n",
       "      <td>2.54</td>\n",
       "      <td>6.57</td>\n",
       "      <td>4.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ace</td>\n",
       "      <td>6.88</td>\n",
       "      <td>5.50</td>\n",
       "      <td>6.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ache</td>\n",
       "      <td>2.46</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>achievement</td>\n",
       "      <td>7.89</td>\n",
       "      <td>5.53</td>\n",
       "      <td>6.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>acre</td>\n",
       "      <td>5.66</td>\n",
       "      <td>4.90</td>\n",
       "      <td>6.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>action</td>\n",
       "      <td>6.63</td>\n",
       "      <td>6.53</td>\n",
       "      <td>5.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>activate</td>\n",
       "      <td>5.46</td>\n",
       "      <td>4.86</td>\n",
       "      <td>5.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>actor</td>\n",
       "      <td>7.13</td>\n",
       "      <td>6.07</td>\n",
       "      <td>4.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ad</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.29</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>adapt</td>\n",
       "      <td>5.72</td>\n",
       "      <td>4.52</td>\n",
       "      <td>5.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>addict</td>\n",
       "      <td>2.48</td>\n",
       "      <td>5.66</td>\n",
       "      <td>3.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>addicted</td>\n",
       "      <td>2.51</td>\n",
       "      <td>4.81</td>\n",
       "      <td>3.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>adhere</td>\n",
       "      <td>5.03</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>adjust</td>\n",
       "      <td>5.25</td>\n",
       "      <td>5.39</td>\n",
       "      <td>4.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>admire</td>\n",
       "      <td>7.63</td>\n",
       "      <td>6.20</td>\n",
       "      <td>6.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>admired</td>\n",
       "      <td>7.74</td>\n",
       "      <td>6.11</td>\n",
       "      <td>7.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>admit</td>\n",
       "      <td>4.93</td>\n",
       "      <td>4.97</td>\n",
       "      <td>4.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2446</th>\n",
       "      <td>wishful</td>\n",
       "      <td>7.50</td>\n",
       "      <td>5.57</td>\n",
       "      <td>5.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>wit</td>\n",
       "      <td>7.32</td>\n",
       "      <td>5.42</td>\n",
       "      <td>6.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2448</th>\n",
       "      <td>wolf</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.70</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2449</th>\n",
       "      <td>woman</td>\n",
       "      <td>6.64</td>\n",
       "      <td>5.32</td>\n",
       "      <td>6.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2450</th>\n",
       "      <td>wonder</td>\n",
       "      <td>6.03</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2451</th>\n",
       "      <td>wood</td>\n",
       "      <td>5.86</td>\n",
       "      <td>4.67</td>\n",
       "      <td>5.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>wool</td>\n",
       "      <td>5.27</td>\n",
       "      <td>3.60</td>\n",
       "      <td>5.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2453</th>\n",
       "      <td>work</td>\n",
       "      <td>3.96</td>\n",
       "      <td>5.11</td>\n",
       "      <td>4.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454</th>\n",
       "      <td>worker</td>\n",
       "      <td>5.07</td>\n",
       "      <td>4.73</td>\n",
       "      <td>5.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>world</td>\n",
       "      <td>6.50</td>\n",
       "      <td>5.32</td>\n",
       "      <td>5.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2456</th>\n",
       "      <td>worry</td>\n",
       "      <td>2.31</td>\n",
       "      <td>6.00</td>\n",
       "      <td>2.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2457</th>\n",
       "      <td>worth</td>\n",
       "      <td>6.15</td>\n",
       "      <td>4.62</td>\n",
       "      <td>5.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2458</th>\n",
       "      <td>wounds</td>\n",
       "      <td>2.51</td>\n",
       "      <td>5.82</td>\n",
       "      <td>3.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2459</th>\n",
       "      <td>wrath</td>\n",
       "      <td>3.47</td>\n",
       "      <td>5.60</td>\n",
       "      <td>4.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2460</th>\n",
       "      <td>wreath</td>\n",
       "      <td>6.07</td>\n",
       "      <td>4.64</td>\n",
       "      <td>5.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2461</th>\n",
       "      <td>wring</td>\n",
       "      <td>4.81</td>\n",
       "      <td>4.78</td>\n",
       "      <td>5.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2462</th>\n",
       "      <td>writer</td>\n",
       "      <td>5.52</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2463</th>\n",
       "      <td>wrong</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4.67</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2464</th>\n",
       "      <td>yacht</td>\n",
       "      <td>6.95</td>\n",
       "      <td>5.61</td>\n",
       "      <td>6.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2465</th>\n",
       "      <td>year</td>\n",
       "      <td>5.41</td>\n",
       "      <td>4.22</td>\n",
       "      <td>5.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>yellow</td>\n",
       "      <td>5.61</td>\n",
       "      <td>4.43</td>\n",
       "      <td>5.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2467</th>\n",
       "      <td>yelp</td>\n",
       "      <td>3.69</td>\n",
       "      <td>5.73</td>\n",
       "      <td>4.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>yolk</td>\n",
       "      <td>5.48</td>\n",
       "      <td>4.07</td>\n",
       "      <td>5.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>young</td>\n",
       "      <td>6.89</td>\n",
       "      <td>5.64</td>\n",
       "      <td>5.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>youth</td>\n",
       "      <td>6.75</td>\n",
       "      <td>5.67</td>\n",
       "      <td>5.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>zeal</td>\n",
       "      <td>6.15</td>\n",
       "      <td>5.41</td>\n",
       "      <td>5.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>zealous</td>\n",
       "      <td>5.67</td>\n",
       "      <td>5.47</td>\n",
       "      <td>5.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>zest</td>\n",
       "      <td>6.79</td>\n",
       "      <td>5.59</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>zipper</td>\n",
       "      <td>5.39</td>\n",
       "      <td>5.19</td>\n",
       "      <td>5.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>zoom</td>\n",
       "      <td>6.56</td>\n",
       "      <td>5.88</td>\n",
       "      <td>5.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2476 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word  ValMn  AroMn  DomMn\n",
       "0       abduction   2.76   5.53   3.49\n",
       "1            able   6.74   4.30   6.83\n",
       "2        abortion   3.50   5.39   4.59\n",
       "3          absent   3.69   4.73   4.35\n",
       "4          absurd   4.26   4.36   4.73\n",
       "5       abundance   6.59   5.51   5.80\n",
       "6           abuse   1.80   6.83   3.69\n",
       "7          accept   6.80   5.53   5.41\n",
       "8      acceptance   7.98   5.40   6.64\n",
       "9          access   6.14   5.07   6.25\n",
       "10       accident   2.05   6.26   3.76\n",
       "11         accord   5.53   4.24   5.31\n",
       "12         accost   4.28   5.24   4.38\n",
       "13         accuse   2.54   6.57   4.07\n",
       "14            ace   6.88   5.50   6.39\n",
       "15           ache   2.46   5.00   3.54\n",
       "16    achievement   7.89   5.53   6.56\n",
       "17           acre   5.66   4.90   6.04\n",
       "18         action   6.63   6.53   5.63\n",
       "19       activate   5.46   4.86   5.43\n",
       "20          actor   7.13   6.07   4.97\n",
       "21             ad   5.00   4.29   5.00\n",
       "22          adapt   5.72   4.52   5.43\n",
       "23         addict   2.48   5.66   3.72\n",
       "24       addicted   2.51   4.81   3.46\n",
       "25         adhere   5.03   4.07   4.33\n",
       "26         adjust   5.25   5.39   4.86\n",
       "27         admire   7.63   6.20   6.27\n",
       "28        admired   7.74   6.11   7.53\n",
       "29          admit   4.93   4.97   4.45\n",
       "...           ...    ...    ...    ...\n",
       "2446      wishful   7.50   5.57   5.27\n",
       "2447          wit   7.32   5.42   6.38\n",
       "2448         wolf   5.00   6.70   4.33\n",
       "2449        woman   6.64   5.32   6.33\n",
       "2450       wonder   6.03   5.00   5.32\n",
       "2451         wood   5.86   4.67   5.59\n",
       "2452         wool   5.27   3.60   5.17\n",
       "2453         work   3.96   5.11   4.11\n",
       "2454       worker   5.07   4.73   5.27\n",
       "2455        world   6.50   5.32   5.26\n",
       "2456        worry   2.31   6.00   2.96\n",
       "2457        worth   6.15   4.62   5.23\n",
       "2458       wounds   2.51   5.82   3.92\n",
       "2459        wrath   3.47   5.60   4.23\n",
       "2460       wreath   6.07   4.64   5.14\n",
       "2461        wring   4.81   4.78   5.03\n",
       "2462       writer   5.52   4.33   4.73\n",
       "2463        wrong   2.93   4.67   3.30\n",
       "2464        yacht   6.95   5.61   6.10\n",
       "2465         year   5.41   4.22   5.25\n",
       "2466       yellow   5.61   4.43   5.47\n",
       "2467         yelp   3.69   5.73   4.27\n",
       "2468         yolk   5.48   4.07   5.04\n",
       "2469        young   6.89   5.64   5.30\n",
       "2470        youth   6.75   5.67   5.11\n",
       "2471         zeal   6.15   5.41   5.52\n",
       "2472      zealous   5.67   5.47   5.60\n",
       "2473         zest   6.79   5.59   6.00\n",
       "2474       zipper   5.39   5.19   5.63\n",
       "2475         zoom   6.56   5.88   5.91\n",
       "\n",
       "[2476 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anew_sliced = anew_df[['Word','ValMn', 'AroMn', 'DomMn']] \n",
    "anew_sliced #subsetting the mean ratings from ANEW df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>clinton_WC</th>\n",
       "      <th>trump_WC</th>\n",
       "      <th>ValMn</th>\n",
       "      <th>AroMn</th>\n",
       "      <th>DomMn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abduction</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.76</td>\n",
       "      <td>5.53</td>\n",
       "      <td>3.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>able</td>\n",
       "      <td>66.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>6.74</td>\n",
       "      <td>4.30</td>\n",
       "      <td>6.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abortion</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>5.39</td>\n",
       "      <td>4.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>absent</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.69</td>\n",
       "      <td>4.73</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>absurd</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.26</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abundance</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.59</td>\n",
       "      <td>5.51</td>\n",
       "      <td>5.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abuse</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>6.83</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>accept</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.80</td>\n",
       "      <td>5.53</td>\n",
       "      <td>5.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>acceptance</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.98</td>\n",
       "      <td>5.40</td>\n",
       "      <td>6.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>access</td>\n",
       "      <td>22.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>6.14</td>\n",
       "      <td>5.07</td>\n",
       "      <td>6.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>accident</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>6.26</td>\n",
       "      <td>3.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>accord</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.53</td>\n",
       "      <td>4.24</td>\n",
       "      <td>5.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>accost</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.28</td>\n",
       "      <td>5.24</td>\n",
       "      <td>4.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>accuse</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.54</td>\n",
       "      <td>6.57</td>\n",
       "      <td>4.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ace</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.88</td>\n",
       "      <td>5.50</td>\n",
       "      <td>6.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ache</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.46</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>achievement</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.89</td>\n",
       "      <td>5.53</td>\n",
       "      <td>6.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>acre</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.66</td>\n",
       "      <td>4.90</td>\n",
       "      <td>6.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>action</td>\n",
       "      <td>17.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6.63</td>\n",
       "      <td>6.53</td>\n",
       "      <td>5.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>activate</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.46</td>\n",
       "      <td>4.86</td>\n",
       "      <td>5.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>actor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.13</td>\n",
       "      <td>6.07</td>\n",
       "      <td>4.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ad</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.29</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>adapt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.72</td>\n",
       "      <td>4.52</td>\n",
       "      <td>5.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>addict</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.48</td>\n",
       "      <td>5.66</td>\n",
       "      <td>3.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>addicted</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.51</td>\n",
       "      <td>4.81</td>\n",
       "      <td>3.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>adhere</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.03</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>adjust</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.25</td>\n",
       "      <td>5.39</td>\n",
       "      <td>4.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>admire</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.63</td>\n",
       "      <td>6.20</td>\n",
       "      <td>6.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>admired</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.74</td>\n",
       "      <td>6.11</td>\n",
       "      <td>7.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>admit</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.93</td>\n",
       "      <td>4.97</td>\n",
       "      <td>4.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2456</th>\n",
       "      <td>wishful</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.50</td>\n",
       "      <td>5.57</td>\n",
       "      <td>5.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2457</th>\n",
       "      <td>wit</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.32</td>\n",
       "      <td>5.42</td>\n",
       "      <td>6.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2458</th>\n",
       "      <td>wolf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.70</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2459</th>\n",
       "      <td>woman</td>\n",
       "      <td>30.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>6.64</td>\n",
       "      <td>5.32</td>\n",
       "      <td>6.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2460</th>\n",
       "      <td>wonder</td>\n",
       "      <td>12.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>6.03</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2461</th>\n",
       "      <td>wood</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.86</td>\n",
       "      <td>4.67</td>\n",
       "      <td>5.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2462</th>\n",
       "      <td>wool</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.27</td>\n",
       "      <td>3.60</td>\n",
       "      <td>5.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2463</th>\n",
       "      <td>work</td>\n",
       "      <td>341.0</td>\n",
       "      <td>381.0</td>\n",
       "      <td>3.96</td>\n",
       "      <td>5.11</td>\n",
       "      <td>4.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2464</th>\n",
       "      <td>worker</td>\n",
       "      <td>11.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5.07</td>\n",
       "      <td>4.73</td>\n",
       "      <td>5.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2465</th>\n",
       "      <td>world</td>\n",
       "      <td>130.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>6.50</td>\n",
       "      <td>5.32</td>\n",
       "      <td>5.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>worry</td>\n",
       "      <td>5.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>6.00</td>\n",
       "      <td>2.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2467</th>\n",
       "      <td>worth</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.15</td>\n",
       "      <td>4.62</td>\n",
       "      <td>5.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>wounds</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.51</td>\n",
       "      <td>5.82</td>\n",
       "      <td>3.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>wrath</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.47</td>\n",
       "      <td>5.60</td>\n",
       "      <td>4.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>wreath</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.07</td>\n",
       "      <td>4.64</td>\n",
       "      <td>5.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>wring</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.81</td>\n",
       "      <td>4.78</td>\n",
       "      <td>5.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>writer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.52</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>wrong</td>\n",
       "      <td>39.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4.67</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>yacht</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.95</td>\n",
       "      <td>5.61</td>\n",
       "      <td>6.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>year</td>\n",
       "      <td>71.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>5.41</td>\n",
       "      <td>4.22</td>\n",
       "      <td>5.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>yellow</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.61</td>\n",
       "      <td>4.43</td>\n",
       "      <td>5.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>yelp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.69</td>\n",
       "      <td>5.73</td>\n",
       "      <td>4.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>yolk</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.48</td>\n",
       "      <td>4.07</td>\n",
       "      <td>5.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>young</td>\n",
       "      <td>135.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>6.89</td>\n",
       "      <td>5.64</td>\n",
       "      <td>5.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>youth</td>\n",
       "      <td>3.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>6.75</td>\n",
       "      <td>5.67</td>\n",
       "      <td>5.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>zeal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.15</td>\n",
       "      <td>5.41</td>\n",
       "      <td>5.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>zealous</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.67</td>\n",
       "      <td>5.47</td>\n",
       "      <td>5.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>zest</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.79</td>\n",
       "      <td>5.59</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>zipper</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.39</td>\n",
       "      <td>5.19</td>\n",
       "      <td>5.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2485</th>\n",
       "      <td>zoom</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.56</td>\n",
       "      <td>5.88</td>\n",
       "      <td>5.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2486 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word  clinton_WC  trump_WC  ValMn  AroMn  DomMn\n",
       "0       abduction         0.0       0.0   2.76   5.53   3.49\n",
       "1            able        66.0      96.0   6.74   4.30   6.83\n",
       "2        abortion         0.0       0.0   3.50   5.39   4.59\n",
       "3          absent         0.0       0.0   3.69   4.73   4.35\n",
       "4          absurd         1.0       0.0   4.26   4.36   4.73\n",
       "5       abundance         0.0       0.0   6.59   5.51   5.80\n",
       "6           abuse         4.0       3.0   1.80   6.83   3.69\n",
       "7          accept         7.0      13.0   6.80   5.53   5.41\n",
       "8      acceptance         1.0       1.0   7.98   5.40   6.64\n",
       "9          access        22.0      34.0   6.14   5.07   6.25\n",
       "10       accident         2.0       3.0   2.05   6.26   3.76\n",
       "11         accord         0.0       0.0   5.53   4.24   5.31\n",
       "12         accost         0.0       0.0   4.28   5.24   4.38\n",
       "13         accuse         0.0       2.0   2.54   6.57   4.07\n",
       "14            ace         0.0       0.0   6.88   5.50   6.39\n",
       "15           ache         0.0       0.0   2.46   5.00   3.54\n",
       "16    achievement         3.0       2.0   7.89   5.53   6.56\n",
       "17           acre         0.0       0.0   5.66   4.90   6.04\n",
       "18         action        17.0      26.0   6.63   6.53   5.63\n",
       "19       activate         0.0       0.0   5.46   4.86   5.43\n",
       "20          actor         0.0       2.0   7.13   6.07   4.97\n",
       "21             ad         4.0      16.0   5.00   4.29   5.00\n",
       "22          adapt         0.0       1.0   5.72   4.52   5.43\n",
       "23         addict         0.0       0.0   2.48   5.66   3.72\n",
       "24       addicted         0.0      12.0   2.51   4.81   3.46\n",
       "25         adhere         0.0       1.0   5.03   4.07   4.33\n",
       "26         adjust         0.0       1.0   5.25   5.39   4.86\n",
       "27         admire         5.0       0.0   7.63   6.20   6.27\n",
       "28        admired         3.0       0.0   7.74   6.11   7.53\n",
       "29          admit         5.0      20.0   4.93   4.97   4.45\n",
       "...           ...         ...       ...    ...    ...    ...\n",
       "2456      wishful         0.0       0.0   7.50   5.57   5.27\n",
       "2457          wit         0.0       0.0   7.32   5.42   6.38\n",
       "2458         wolf         0.0       4.0   5.00   6.70   4.33\n",
       "2459        woman        30.0     101.0   6.64   5.32   6.33\n",
       "2460       wonder        12.0      55.0   6.03   5.00   5.32\n",
       "2461         wood         0.0       0.0   5.86   4.67   5.59\n",
       "2462         wool         0.0       0.0   5.27   3.60   5.17\n",
       "2463         work       341.0     381.0   3.96   5.11   4.11\n",
       "2464       worker        11.0      36.0   5.07   4.73   5.27\n",
       "2465        world       130.0     552.0   6.50   5.32   5.26\n",
       "2466        worry         5.0      76.0   2.31   6.00   2.96\n",
       "2467        worth        15.0       8.0   6.15   4.62   5.23\n",
       "2468       wounds         1.0       1.0   2.51   5.82   3.92\n",
       "2469        wrath         0.0       0.0   3.47   5.60   4.23\n",
       "2470       wreath         0.0       0.0   6.07   4.64   5.14\n",
       "2471        wring         0.0       0.0   4.81   4.78   5.03\n",
       "2472       writer         0.0       4.0   5.52   4.33   4.73\n",
       "2473        wrong        39.0     113.0   2.93   4.67   3.30\n",
       "2474        yacht         0.0       0.0   6.95   5.61   6.10\n",
       "2475         year        71.0     221.0   5.41   4.22   5.25\n",
       "2476       yellow         0.0       5.0   5.61   4.43   5.47\n",
       "2477         yelp         0.0       0.0   3.69   5.73   4.27\n",
       "2478         yolk         0.0       0.0   5.48   4.07   5.04\n",
       "2479        young       135.0      62.0   6.89   5.64   5.30\n",
       "2480        youth         3.0      81.0   6.75   5.67   5.11\n",
       "2481         zeal         0.0       0.0   6.15   5.41   5.52\n",
       "2482      zealous         0.0       0.0   5.67   5.47   5.60\n",
       "2483         zest         0.0       0.0   6.79   5.59   6.00\n",
       "2484       zipper         0.0       0.0   5.39   5.19   5.63\n",
       "2485         zoom         0.0       0.0   6.56   5.88   5.91\n",
       "\n",
       "[2486 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined = pd.merge(df_long, anew_sliced)\n",
    "df_combined #combining df_long with anew_sliced into one dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now perform the calculation of weighted means for each word.\n",
    "\n",
    "Below, each line of code calculates the product of each word's count in the corpus with the associated mean ratings of Valence, Arousal, and Dominance, and stores the value in a new appended column. The column multiplications are calcualted for all the rows (words) in the dataframe.\n",
    "\n",
    "For example, the first line of code (below) calculates the weighted valence of each word in the Clinton corpus, based on how frequently that word occurs in the corpus (the word count). It takes clinton_WC and multiplies it by ValMn, and stores it in a new column called \"clinton_Val\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>clinton_WC</th>\n",
       "      <th>trump_WC</th>\n",
       "      <th>ValMn</th>\n",
       "      <th>AroMn</th>\n",
       "      <th>DomMn</th>\n",
       "      <th>clinton_Val</th>\n",
       "      <th>trump_Val</th>\n",
       "      <th>clinton_Aro</th>\n",
       "      <th>trump_Aro</th>\n",
       "      <th>clinton_Dom</th>\n",
       "      <th>trump_Dom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abduction</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.76</td>\n",
       "      <td>5.53</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>able</td>\n",
       "      <td>66.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>6.74</td>\n",
       "      <td>4.30</td>\n",
       "      <td>6.83</td>\n",
       "      <td>444.84</td>\n",
       "      <td>647.04</td>\n",
       "      <td>283.80</td>\n",
       "      <td>412.80</td>\n",
       "      <td>450.78</td>\n",
       "      <td>655.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abortion</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>5.39</td>\n",
       "      <td>4.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>absent</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.69</td>\n",
       "      <td>4.73</td>\n",
       "      <td>4.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>absurd</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.26</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.73</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.73</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abundance</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.59</td>\n",
       "      <td>5.51</td>\n",
       "      <td>5.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abuse</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>6.83</td>\n",
       "      <td>3.69</td>\n",
       "      <td>7.20</td>\n",
       "      <td>5.40</td>\n",
       "      <td>27.32</td>\n",
       "      <td>20.49</td>\n",
       "      <td>14.76</td>\n",
       "      <td>11.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>accept</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.80</td>\n",
       "      <td>5.53</td>\n",
       "      <td>5.41</td>\n",
       "      <td>47.60</td>\n",
       "      <td>88.40</td>\n",
       "      <td>38.71</td>\n",
       "      <td>71.89</td>\n",
       "      <td>37.87</td>\n",
       "      <td>70.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>acceptance</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.98</td>\n",
       "      <td>5.40</td>\n",
       "      <td>6.64</td>\n",
       "      <td>7.98</td>\n",
       "      <td>7.98</td>\n",
       "      <td>5.40</td>\n",
       "      <td>5.40</td>\n",
       "      <td>6.64</td>\n",
       "      <td>6.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>access</td>\n",
       "      <td>22.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>6.14</td>\n",
       "      <td>5.07</td>\n",
       "      <td>6.25</td>\n",
       "      <td>135.08</td>\n",
       "      <td>208.76</td>\n",
       "      <td>111.54</td>\n",
       "      <td>172.38</td>\n",
       "      <td>137.50</td>\n",
       "      <td>212.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>accident</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>6.26</td>\n",
       "      <td>3.76</td>\n",
       "      <td>4.10</td>\n",
       "      <td>6.15</td>\n",
       "      <td>12.52</td>\n",
       "      <td>18.78</td>\n",
       "      <td>7.52</td>\n",
       "      <td>11.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>accord</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.53</td>\n",
       "      <td>4.24</td>\n",
       "      <td>5.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>accost</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.28</td>\n",
       "      <td>5.24</td>\n",
       "      <td>4.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>accuse</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.54</td>\n",
       "      <td>6.57</td>\n",
       "      <td>4.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ace</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.88</td>\n",
       "      <td>5.50</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ache</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.46</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>achievement</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.89</td>\n",
       "      <td>5.53</td>\n",
       "      <td>6.56</td>\n",
       "      <td>23.67</td>\n",
       "      <td>15.78</td>\n",
       "      <td>16.59</td>\n",
       "      <td>11.06</td>\n",
       "      <td>19.68</td>\n",
       "      <td>13.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>acre</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.66</td>\n",
       "      <td>4.90</td>\n",
       "      <td>6.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>action</td>\n",
       "      <td>17.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6.63</td>\n",
       "      <td>6.53</td>\n",
       "      <td>5.63</td>\n",
       "      <td>112.71</td>\n",
       "      <td>172.38</td>\n",
       "      <td>111.01</td>\n",
       "      <td>169.78</td>\n",
       "      <td>95.71</td>\n",
       "      <td>146.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>activate</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.46</td>\n",
       "      <td>4.86</td>\n",
       "      <td>5.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>actor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.13</td>\n",
       "      <td>6.07</td>\n",
       "      <td>4.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ad</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.29</td>\n",
       "      <td>5.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>17.16</td>\n",
       "      <td>68.64</td>\n",
       "      <td>20.00</td>\n",
       "      <td>80.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>adapt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.72</td>\n",
       "      <td>4.52</td>\n",
       "      <td>5.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>addict</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.48</td>\n",
       "      <td>5.66</td>\n",
       "      <td>3.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>addicted</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.51</td>\n",
       "      <td>4.81</td>\n",
       "      <td>3.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>57.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>adhere</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.03</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>adjust</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.25</td>\n",
       "      <td>5.39</td>\n",
       "      <td>4.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>admire</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.63</td>\n",
       "      <td>6.20</td>\n",
       "      <td>6.27</td>\n",
       "      <td>38.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31.35</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>admired</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.74</td>\n",
       "      <td>6.11</td>\n",
       "      <td>7.53</td>\n",
       "      <td>23.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22.59</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>admit</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.93</td>\n",
       "      <td>4.97</td>\n",
       "      <td>4.45</td>\n",
       "      <td>24.65</td>\n",
       "      <td>98.60</td>\n",
       "      <td>24.85</td>\n",
       "      <td>99.40</td>\n",
       "      <td>22.25</td>\n",
       "      <td>89.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2456</th>\n",
       "      <td>wishful</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.50</td>\n",
       "      <td>5.57</td>\n",
       "      <td>5.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2457</th>\n",
       "      <td>wit</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.32</td>\n",
       "      <td>5.42</td>\n",
       "      <td>6.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2458</th>\n",
       "      <td>wolf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.70</td>\n",
       "      <td>4.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2459</th>\n",
       "      <td>woman</td>\n",
       "      <td>30.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>6.64</td>\n",
       "      <td>5.32</td>\n",
       "      <td>6.33</td>\n",
       "      <td>199.20</td>\n",
       "      <td>670.64</td>\n",
       "      <td>159.60</td>\n",
       "      <td>537.32</td>\n",
       "      <td>189.90</td>\n",
       "      <td>639.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2460</th>\n",
       "      <td>wonder</td>\n",
       "      <td>12.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>6.03</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.32</td>\n",
       "      <td>72.36</td>\n",
       "      <td>331.65</td>\n",
       "      <td>60.00</td>\n",
       "      <td>275.00</td>\n",
       "      <td>63.84</td>\n",
       "      <td>292.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2461</th>\n",
       "      <td>wood</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.86</td>\n",
       "      <td>4.67</td>\n",
       "      <td>5.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2462</th>\n",
       "      <td>wool</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.27</td>\n",
       "      <td>3.60</td>\n",
       "      <td>5.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2463</th>\n",
       "      <td>work</td>\n",
       "      <td>341.0</td>\n",
       "      <td>381.0</td>\n",
       "      <td>3.96</td>\n",
       "      <td>5.11</td>\n",
       "      <td>4.11</td>\n",
       "      <td>1350.36</td>\n",
       "      <td>1508.76</td>\n",
       "      <td>1742.51</td>\n",
       "      <td>1946.91</td>\n",
       "      <td>1401.51</td>\n",
       "      <td>1565.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2464</th>\n",
       "      <td>worker</td>\n",
       "      <td>11.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5.07</td>\n",
       "      <td>4.73</td>\n",
       "      <td>5.27</td>\n",
       "      <td>55.77</td>\n",
       "      <td>182.52</td>\n",
       "      <td>52.03</td>\n",
       "      <td>170.28</td>\n",
       "      <td>57.97</td>\n",
       "      <td>189.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2465</th>\n",
       "      <td>world</td>\n",
       "      <td>130.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>6.50</td>\n",
       "      <td>5.32</td>\n",
       "      <td>5.26</td>\n",
       "      <td>845.00</td>\n",
       "      <td>3588.00</td>\n",
       "      <td>691.60</td>\n",
       "      <td>2936.64</td>\n",
       "      <td>683.80</td>\n",
       "      <td>2903.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>worry</td>\n",
       "      <td>5.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>6.00</td>\n",
       "      <td>2.96</td>\n",
       "      <td>11.55</td>\n",
       "      <td>175.56</td>\n",
       "      <td>30.00</td>\n",
       "      <td>456.00</td>\n",
       "      <td>14.80</td>\n",
       "      <td>224.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2467</th>\n",
       "      <td>worth</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.15</td>\n",
       "      <td>4.62</td>\n",
       "      <td>5.23</td>\n",
       "      <td>92.25</td>\n",
       "      <td>49.20</td>\n",
       "      <td>69.30</td>\n",
       "      <td>36.96</td>\n",
       "      <td>78.45</td>\n",
       "      <td>41.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>wounds</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.51</td>\n",
       "      <td>5.82</td>\n",
       "      <td>3.92</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.51</td>\n",
       "      <td>5.82</td>\n",
       "      <td>5.82</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>wrath</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.47</td>\n",
       "      <td>5.60</td>\n",
       "      <td>4.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>wreath</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.07</td>\n",
       "      <td>4.64</td>\n",
       "      <td>5.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>wring</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.81</td>\n",
       "      <td>4.78</td>\n",
       "      <td>5.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>writer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.52</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>wrong</td>\n",
       "      <td>39.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4.67</td>\n",
       "      <td>3.30</td>\n",
       "      <td>114.27</td>\n",
       "      <td>331.09</td>\n",
       "      <td>182.13</td>\n",
       "      <td>527.71</td>\n",
       "      <td>128.70</td>\n",
       "      <td>372.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>yacht</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.95</td>\n",
       "      <td>5.61</td>\n",
       "      <td>6.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>year</td>\n",
       "      <td>71.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>5.41</td>\n",
       "      <td>4.22</td>\n",
       "      <td>5.25</td>\n",
       "      <td>384.11</td>\n",
       "      <td>1195.61</td>\n",
       "      <td>299.62</td>\n",
       "      <td>932.62</td>\n",
       "      <td>372.75</td>\n",
       "      <td>1160.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>yellow</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.61</td>\n",
       "      <td>4.43</td>\n",
       "      <td>5.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>27.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>yelp</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.69</td>\n",
       "      <td>5.73</td>\n",
       "      <td>4.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>yolk</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.48</td>\n",
       "      <td>4.07</td>\n",
       "      <td>5.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>young</td>\n",
       "      <td>135.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>6.89</td>\n",
       "      <td>5.64</td>\n",
       "      <td>5.30</td>\n",
       "      <td>930.15</td>\n",
       "      <td>427.18</td>\n",
       "      <td>761.40</td>\n",
       "      <td>349.68</td>\n",
       "      <td>715.50</td>\n",
       "      <td>328.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>youth</td>\n",
       "      <td>3.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>6.75</td>\n",
       "      <td>5.67</td>\n",
       "      <td>5.11</td>\n",
       "      <td>20.25</td>\n",
       "      <td>546.75</td>\n",
       "      <td>17.01</td>\n",
       "      <td>459.27</td>\n",
       "      <td>15.33</td>\n",
       "      <td>413.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>zeal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.15</td>\n",
       "      <td>5.41</td>\n",
       "      <td>5.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>zealous</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.67</td>\n",
       "      <td>5.47</td>\n",
       "      <td>5.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>zest</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.79</td>\n",
       "      <td>5.59</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>zipper</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.39</td>\n",
       "      <td>5.19</td>\n",
       "      <td>5.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2485</th>\n",
       "      <td>zoom</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.56</td>\n",
       "      <td>5.88</td>\n",
       "      <td>5.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2486 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word  clinton_WC  trump_WC  ValMn  AroMn  DomMn  clinton_Val  \\\n",
       "0       abduction         0.0       0.0   2.76   5.53   3.49         0.00   \n",
       "1            able        66.0      96.0   6.74   4.30   6.83       444.84   \n",
       "2        abortion         0.0       0.0   3.50   5.39   4.59         0.00   \n",
       "3          absent         0.0       0.0   3.69   4.73   4.35         0.00   \n",
       "4          absurd         1.0       0.0   4.26   4.36   4.73         4.26   \n",
       "5       abundance         0.0       0.0   6.59   5.51   5.80         0.00   \n",
       "6           abuse         4.0       3.0   1.80   6.83   3.69         7.20   \n",
       "7          accept         7.0      13.0   6.80   5.53   5.41        47.60   \n",
       "8      acceptance         1.0       1.0   7.98   5.40   6.64         7.98   \n",
       "9          access        22.0      34.0   6.14   5.07   6.25       135.08   \n",
       "10       accident         2.0       3.0   2.05   6.26   3.76         4.10   \n",
       "11         accord         0.0       0.0   5.53   4.24   5.31         0.00   \n",
       "12         accost         0.0       0.0   4.28   5.24   4.38         0.00   \n",
       "13         accuse         0.0       2.0   2.54   6.57   4.07         0.00   \n",
       "14            ace         0.0       0.0   6.88   5.50   6.39         0.00   \n",
       "15           ache         0.0       0.0   2.46   5.00   3.54         0.00   \n",
       "16    achievement         3.0       2.0   7.89   5.53   6.56        23.67   \n",
       "17           acre         0.0       0.0   5.66   4.90   6.04         0.00   \n",
       "18         action        17.0      26.0   6.63   6.53   5.63       112.71   \n",
       "19       activate         0.0       0.0   5.46   4.86   5.43         0.00   \n",
       "20          actor         0.0       2.0   7.13   6.07   4.97         0.00   \n",
       "21             ad         4.0      16.0   5.00   4.29   5.00        20.00   \n",
       "22          adapt         0.0       1.0   5.72   4.52   5.43         0.00   \n",
       "23         addict         0.0       0.0   2.48   5.66   3.72         0.00   \n",
       "24       addicted         0.0      12.0   2.51   4.81   3.46         0.00   \n",
       "25         adhere         0.0       1.0   5.03   4.07   4.33         0.00   \n",
       "26         adjust         0.0       1.0   5.25   5.39   4.86         0.00   \n",
       "27         admire         5.0       0.0   7.63   6.20   6.27        38.15   \n",
       "28        admired         3.0       0.0   7.74   6.11   7.53        23.22   \n",
       "29          admit         5.0      20.0   4.93   4.97   4.45        24.65   \n",
       "...           ...         ...       ...    ...    ...    ...          ...   \n",
       "2456      wishful         0.0       0.0   7.50   5.57   5.27         0.00   \n",
       "2457          wit         0.0       0.0   7.32   5.42   6.38         0.00   \n",
       "2458         wolf         0.0       4.0   5.00   6.70   4.33         0.00   \n",
       "2459        woman        30.0     101.0   6.64   5.32   6.33       199.20   \n",
       "2460       wonder        12.0      55.0   6.03   5.00   5.32        72.36   \n",
       "2461         wood         0.0       0.0   5.86   4.67   5.59         0.00   \n",
       "2462         wool         0.0       0.0   5.27   3.60   5.17         0.00   \n",
       "2463         work       341.0     381.0   3.96   5.11   4.11      1350.36   \n",
       "2464       worker        11.0      36.0   5.07   4.73   5.27        55.77   \n",
       "2465        world       130.0     552.0   6.50   5.32   5.26       845.00   \n",
       "2466        worry         5.0      76.0   2.31   6.00   2.96        11.55   \n",
       "2467        worth        15.0       8.0   6.15   4.62   5.23        92.25   \n",
       "2468       wounds         1.0       1.0   2.51   5.82   3.92         2.51   \n",
       "2469        wrath         0.0       0.0   3.47   5.60   4.23         0.00   \n",
       "2470       wreath         0.0       0.0   6.07   4.64   5.14         0.00   \n",
       "2471        wring         0.0       0.0   4.81   4.78   5.03         0.00   \n",
       "2472       writer         0.0       4.0   5.52   4.33   4.73         0.00   \n",
       "2473        wrong        39.0     113.0   2.93   4.67   3.30       114.27   \n",
       "2474        yacht         0.0       0.0   6.95   5.61   6.10         0.00   \n",
       "2475         year        71.0     221.0   5.41   4.22   5.25       384.11   \n",
       "2476       yellow         0.0       5.0   5.61   4.43   5.47         0.00   \n",
       "2477         yelp         0.0       0.0   3.69   5.73   4.27         0.00   \n",
       "2478         yolk         0.0       0.0   5.48   4.07   5.04         0.00   \n",
       "2479        young       135.0      62.0   6.89   5.64   5.30       930.15   \n",
       "2480        youth         3.0      81.0   6.75   5.67   5.11        20.25   \n",
       "2481         zeal         0.0       0.0   6.15   5.41   5.52         0.00   \n",
       "2482      zealous         0.0       0.0   5.67   5.47   5.60         0.00   \n",
       "2483         zest         0.0       0.0   6.79   5.59   6.00         0.00   \n",
       "2484       zipper         0.0       0.0   5.39   5.19   5.63         0.00   \n",
       "2485         zoom         0.0       0.0   6.56   5.88   5.91         0.00   \n",
       "\n",
       "      trump_Val  clinton_Aro  trump_Aro  clinton_Dom  trump_Dom  \n",
       "0          0.00         0.00       0.00         0.00       0.00  \n",
       "1        647.04       283.80     412.80       450.78     655.68  \n",
       "2          0.00         0.00       0.00         0.00       0.00  \n",
       "3          0.00         0.00       0.00         0.00       0.00  \n",
       "4          0.00         4.36       0.00         4.73       0.00  \n",
       "5          0.00         0.00       0.00         0.00       0.00  \n",
       "6          5.40        27.32      20.49        14.76      11.07  \n",
       "7         88.40        38.71      71.89        37.87      70.33  \n",
       "8          7.98         5.40       5.40         6.64       6.64  \n",
       "9        208.76       111.54     172.38       137.50     212.50  \n",
       "10         6.15        12.52      18.78         7.52      11.28  \n",
       "11         0.00         0.00       0.00         0.00       0.00  \n",
       "12         0.00         0.00       0.00         0.00       0.00  \n",
       "13         5.08         0.00      13.14         0.00       8.14  \n",
       "14         0.00         0.00       0.00         0.00       0.00  \n",
       "15         0.00         0.00       0.00         0.00       0.00  \n",
       "16        15.78        16.59      11.06        19.68      13.12  \n",
       "17         0.00         0.00       0.00         0.00       0.00  \n",
       "18       172.38       111.01     169.78        95.71     146.38  \n",
       "19         0.00         0.00       0.00         0.00       0.00  \n",
       "20        14.26         0.00      12.14         0.00       9.94  \n",
       "21        80.00        17.16      68.64        20.00      80.00  \n",
       "22         5.72         0.00       4.52         0.00       5.43  \n",
       "23         0.00         0.00       0.00         0.00       0.00  \n",
       "24        30.12         0.00      57.72         0.00      41.52  \n",
       "25         5.03         0.00       4.07         0.00       4.33  \n",
       "26         5.25         0.00       5.39         0.00       4.86  \n",
       "27         0.00        31.00       0.00        31.35       0.00  \n",
       "28         0.00        18.33       0.00        22.59       0.00  \n",
       "29        98.60        24.85      99.40        22.25      89.00  \n",
       "...         ...          ...        ...          ...        ...  \n",
       "2456       0.00         0.00       0.00         0.00       0.00  \n",
       "2457       0.00         0.00       0.00         0.00       0.00  \n",
       "2458      20.00         0.00      26.80         0.00      17.32  \n",
       "2459     670.64       159.60     537.32       189.90     639.33  \n",
       "2460     331.65        60.00     275.00        63.84     292.60  \n",
       "2461       0.00         0.00       0.00         0.00       0.00  \n",
       "2462       0.00         0.00       0.00         0.00       0.00  \n",
       "2463    1508.76      1742.51    1946.91      1401.51    1565.91  \n",
       "2464     182.52        52.03     170.28        57.97     189.72  \n",
       "2465    3588.00       691.60    2936.64       683.80    2903.52  \n",
       "2466     175.56        30.00     456.00        14.80     224.96  \n",
       "2467      49.20        69.30      36.96        78.45      41.84  \n",
       "2468       2.51         5.82       5.82         3.92       3.92  \n",
       "2469       0.00         0.00       0.00         0.00       0.00  \n",
       "2470       0.00         0.00       0.00         0.00       0.00  \n",
       "2471       0.00         0.00       0.00         0.00       0.00  \n",
       "2472      22.08         0.00      17.32         0.00      18.92  \n",
       "2473     331.09       182.13     527.71       128.70     372.90  \n",
       "2474       0.00         0.00       0.00         0.00       0.00  \n",
       "2475    1195.61       299.62     932.62       372.75    1160.25  \n",
       "2476      28.05         0.00      22.15         0.00      27.35  \n",
       "2477       0.00         0.00       0.00         0.00       0.00  \n",
       "2478       0.00         0.00       0.00         0.00       0.00  \n",
       "2479     427.18       761.40     349.68       715.50     328.60  \n",
       "2480     546.75        17.01     459.27        15.33     413.91  \n",
       "2481       0.00         0.00       0.00         0.00       0.00  \n",
       "2482       0.00         0.00       0.00         0.00       0.00  \n",
       "2483       0.00         0.00       0.00         0.00       0.00  \n",
       "2484       0.00         0.00       0.00         0.00       0.00  \n",
       "2485       0.00         0.00       0.00         0.00       0.00  \n",
       "\n",
       "[2486 rows x 12 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WORD COUNTS x VALENCE MEANS:\n",
    "\n",
    "# \"clinton_Val\" = clinton_WC x ValMn\n",
    "df_combined['clinton_Val'] = df_combined.apply(lambda row: (row['clinton_WC']*row['ValMn']), axis=1)\n",
    "\n",
    "# \"trump_Val\" = trump_WC x ValMn\n",
    "df_combined['trump_Val'] = df_combined.apply(lambda row: (row['trump_WC']*row['ValMn']), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# WORD COUNTS x AROUSAL MEANS:\n",
    "\n",
    "# \"clinton_Aro\" = clinton_WC x AroMn\n",
    "df_combined['clinton_Aro'] = df_combined.apply(lambda row: (row['clinton_WC']*row['AroMn']), axis=1)\n",
    "\n",
    "# \"trump_Aro\" = trump_WC x AroMn\n",
    "df_combined['trump_Aro'] = df_combined.apply(lambda row: (row['trump_WC']*row['AroMn']), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# WORD COUNTS x DOMINANCE MEANS:\n",
    "\n",
    "# \"clinton_Dom\" = clinton_WC x DomMn\n",
    "df_combined['clinton_Dom'] = df_combined.apply(lambda row: (row['clinton_WC']*row['DomMn']), axis=1)\n",
    "\n",
    "# \"trump_Val\" = trump_WC x ValMn\n",
    "df_combined['trump_Dom'] = df_combined.apply(lambda row: (row['trump_WC']*row['DomMn']), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform calculation of weighted MEANS for valence, arousal, and dominance (across all words)\n",
    "\n",
    "Now that we have the weighted means *for each word*, we can calculate the weighted means across all words (for Trump and Clinton, respectively). This would be the overall \"affectiveness\" of each corpus on each affective dimension, based on the words in ANEW. It is calculated by summing the weighed means across all the words, and dividing that sum by the total number of words from that category (valence, arousal, or dominance) that were used by that candidate. This provided us with an average measure for each of those values. This approach was necessary because ANEW uses a 1-9 likert scale to qualify each of the measures rather than using negative numbers. So merely summing the values doesn’t reflect whether each candidate was more negative or positive. \n",
    "\n",
    "\n",
    "#### Overall weighted means for VALENCE in each corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.7857673861\n",
      "263.2918767\n"
     ]
    }
   ],
   "source": [
    "#Mean of all values in \"clinton_Val\" column (summing across all words)\n",
    "Mean_clinton_Val = (df_combined['clinton_Val'].values.sum())/((df_combined['clinton_Val'] != 0).sum())\n",
    "print(Mean_clinton_Val)\n",
    "\n",
    "#Sum of all values in \"trump_Val\" column (summing across all words)\n",
    "Mean_trump_Val = (df_combined['trump_Val'].values.sum())/((df_combined['trump_Val'] != 0).sum())\n",
    "print(Mean_trump_Val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted means for AROUSAL in each corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.305383693\n",
      "240.275965549\n"
     ]
    }
   ],
   "source": [
    "#Sum of all values in \"clinton_Aro\" column (summing across all words)\n",
    "Mean_clinton_Aro = (df_combined['clinton_Aro'].values.sum())/((df_combined['clinton_Aro'] != 0).sum())\n",
    "print(Mean_clinton_Aro)\n",
    "\n",
    "#Sum of all values in \"trump_Aro\" column (summing across all words)\n",
    "Mean_trump_Aro = (df_combined['trump_Aro'].values.sum())/((df_combined['trump_Aro'] != 0).sum()) \n",
    "print(Mean_trump_Aro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted means for DOMINANCE in each corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.4245683453\n",
      "244.891359927\n"
     ]
    }
   ],
   "source": [
    "#Sum of all values in \"clinton_Dom\" column (summing across all words)\n",
    "Mean_clinton_Dom = (df_combined['clinton_Dom'].values.sum())/((df_combined['clinton_Dom'] != 0).sum())\n",
    "print(Mean_clinton_Dom)\n",
    "\n",
    "#Sum of all values in \"trump_Dom\" column (summing across all words)\n",
    "Mean_trump_Dom = (df_combined['trump_Dom'].values.sum())/((df_combined['trump_Dom'] != 0).sum())\n",
    "print(Mean_trump_Dom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 6 weighted means that we just calculated for each corpus, we will store them in a new dataframe so it's easier to compare the values.\n",
    "\n",
    "First, we'll store the weighted means in 2 separate lists for Trump and Clinton, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Storing the calculated weighted means in 2 separate lists for Trump corpus and Clinton corpus\n",
    "trump_summed = ['Trump', Mean_trump_Val, Mean_trump_Aro, Mean_trump_Dom]\n",
    "clinton_summed = ['Clinton', Mean_clinton_Val, Mean_clinton_Aro, Mean_clinton_Dom]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will combine the two lists into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Candidate</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Arousal</th>\n",
       "      <th>Dominance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Clinton</th>\n",
       "      <td>Clinton</td>\n",
       "      <td>95.7858</td>\n",
       "      <td>84.3054</td>\n",
       "      <td>87.4246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trump</th>\n",
       "      <td>Trump</td>\n",
       "      <td>263.292</td>\n",
       "      <td>240.276</td>\n",
       "      <td>244.891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Candidate  Valence  Arousal Dominance\n",
       "Clinton   Clinton  95.7858  84.3054   87.4246\n",
       "Trump       Trump  263.292  240.276   244.891"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a new dataframe that will store the calculated weighted means\n",
    "sums_df = pd.DataFrame({'Trump': trump_summed,'Clinton': clinton_summed})\n",
    "sums_df = sums_df.transpose()\n",
    "sums_df.columns = ['Candidate', 'Valence', 'Arousal', 'Dominance']\n",
    "sums_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clinton clinton_Val    0.0\n",
      "dtype: float64 clinton_Val    5.87982\n",
      "dtype: float64\n",
      "Trump trump_Val    0.0\n",
      "dtype: float64 trump_Val    20.966591\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#range of valence for each candidate \n",
    "clinton_max = df_combined[['clinton_Val']].max(axis=0)/((df_combined['clinton_Val'] != 0).sum())\n",
    "trump_max = df_combined[['trump_Val']].max(axis=0)/((df_combined['trump_Val'] != 0).sum())\n",
    "\n",
    "clinton_min = df_combined[['clinton_Val']].min(axis=0)/((df_combined['clinton_Val'] != 0).sum())\n",
    "trump_min = df_combined[['trump_Val']].min(axis=0)/((df_combined['trump_Val'] != 0).sum())\n",
    "\n",
    "print('Clinton', clinton_min, clinton_max)\n",
    "print('Trump', trump_min, trump_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical analysis: Performing t-test on the weighted means for each corpus ##\n",
    "\n",
    "Next, we decided to perform a t-test to see whether the weighted means for valence, arousal, and dominance for Clinton and Trump were statistically significant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Independent samples t-test: comparing the weighted mean **VALENCE** ratings for Clinton vs. Trump:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttest_ind:            t = -5.34808  p = 9.61331e-08\n"
     ]
    }
   ],
   "source": [
    "# define a and b as the weighted valence means for Clinton and Trump (pulled out the relevant columns from df_combined)\n",
    "a = df_combined['clinton_Val'].values\n",
    "b = df_combined['trump_Val'].values\n",
    "\n",
    "\n",
    "# perform t-test\n",
    "t, p = ttest_ind(a, b, equal_var=False)\n",
    "print(\"ttest_ind:            t = %g  p = %g\" % (t, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Independent samples t-test: comparing the weighted mean **AROUSAL** ratings for Clinton vs. Trump:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttest_ind:            t = -5.82016  p = 6.5493e-09\n"
     ]
    }
   ],
   "source": [
    "# define a and b as the weighted arousal means for Clinton and Trump (pulled out the relevant columns from df_combined)\n",
    "a = df_combined['clinton_Aro'].values\n",
    "b = df_combined['trump_Aro'].values\n",
    "\n",
    "\n",
    "# perform t-test\n",
    "t, p = ttest_ind(a, b, equal_var=False)\n",
    "print(\"ttest_ind:            t = %g  p = %g\" % (t, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Independent samples t-test: comparing the weighted mean **DOMINANCE** ratings for Clinton vs. Trump:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttest_ind:            t = -5.5498  p = 3.12978e-08\n"
     ]
    }
   ],
   "source": [
    "# define a and b as the weighted dominance means for Clinton and Trump (pulled out the relevant columns from df_combined)\n",
    "a = df_combined['clinton_Dom'].values\n",
    "b = df_combined['trump_Dom'].values\n",
    "\n",
    "\n",
    "# perform t-test\n",
    "t, p = ttest_ind(a, b, equal_var=False)\n",
    "print(\"ttest_ind:            t = %g  p = %g\" % (t, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above confirms that the overall weighted mean ratings for valence, arousal, and dominance in the Trump corpus vs. Clinton corpus were statistically significant. Trump had significantly higher weighed means on all 3 dimensions of affectiveness, suggesting that Trump's speeches had higher valence (t = -5.34, p <.001), arousal (t = -5.82, p < .0001), and dominance (t = -5.55, p < .001) than Clinton's speeches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of the calculated weighted means:\n",
    "\n",
    "This first round of analysis demonstrates that by comparing average values of valence, arousal, and dominance across all campaign speeches for both candidates, Trump emerged as the front runner on all three accounts. \n",
    "\n",
    "His speeches were higher in valence, the content had a higher arousal rate, and he displayed greater levels of dominance in his speech compared to Hillary. The valence findings initially threw me off, and were a bit unexpected...until we realized how many positive qualifiers and adjectives he tended to use in his speeches (i.e. huuuuuuge, very, incredible, best). In a way, this made me realize how it could be easy for his fans and listeners to be swayed by this exaggerated positive language, and gloss over the bullying, empty quality of his speeches. \n",
    "\n",
    "Trump's higher valence ratings also match this story of greater exaggeration use. When examining the range of valence exhibited by each candidate, Trump had a larger emotional valence range than Hillary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots\n",
    "\n",
    "### Most frequent words for each candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Word  frequency\n",
      "0      people        669\n",
      "1        know        622\n",
      "2       going        553\n",
      "3        want        491\n",
      "4         get        398\n",
      "5     america        388\n",
      "6        make        379\n",
      "7        work        341\n",
      "8     country        338\n",
      "9       trump        335\n",
      "10  president        334\n",
      "11         us        314\n",
      "12      think        297\n",
      "13       said        293\n",
      "14        got        283\n",
      "15        one        272\n",
      "16      thats        272\n",
      "17   together        257\n",
      "18     donald        256\n",
      "19       well        255\n",
      "       Word  frequency\n",
      "0     going       5186\n",
      "1    people       3155\n",
      "2      know       2284\n",
      "3   country       1848\n",
      "4      dont       1772\n",
      "5     great       1729\n",
      "6      said       1586\n",
      "7     right       1515\n",
      "8       one       1504\n",
      "9    theyre       1462\n",
      "10  hillary       1460\n",
      "11      get       1381\n",
      "12     want       1360\n",
      "13     like       1344\n",
      "14    thats       1265\n",
      "15     jobs       1253\n",
      "16       im       1160\n",
      "17  clinton       1142\n",
      "18    think       1070\n",
      "19      say       1070\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Calculate frequency distribution\n",
    "clinton_fdist = nltk.FreqDist(clean_clinton)\n",
    "top20clinton = pd.DataFrame(clinton_fdist.most_common(20))\n",
    "top20clinton.columns = ['Word', 'frequency']\n",
    "\n",
    "trump_fdist = nltk.FreqDist(clean_trump)\n",
    "trump_fdist.most_common(20)\n",
    "top20trump = pd.DataFrame(trump_fdist.most_common(20))\n",
    "top20trump.columns = ['Word', 'frequency']\n",
    "print(top20clinton)\n",
    "print(top20trump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>frequency_trump</th>\n",
       "      <th>frequency_clinton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>going</td>\n",
       "      <td>5186.0</td>\n",
       "      <td>553.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>people</td>\n",
       "      <td>3155.0</td>\n",
       "      <td>669.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>know</td>\n",
       "      <td>2284.0</td>\n",
       "      <td>622.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>country</td>\n",
       "      <td>1848.0</td>\n",
       "      <td>338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dont</td>\n",
       "      <td>1772.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>great</td>\n",
       "      <td>1729.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>said</td>\n",
       "      <td>1586.0</td>\n",
       "      <td>293.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>right</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>one</td>\n",
       "      <td>1504.0</td>\n",
       "      <td>272.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>theyre</td>\n",
       "      <td>1462.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hillary</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>get</td>\n",
       "      <td>1381.0</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>want</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>491.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>like</td>\n",
       "      <td>1344.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>thats</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>272.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>jobs</td>\n",
       "      <td>1253.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>im</td>\n",
       "      <td>1160.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>clinton</td>\n",
       "      <td>1142.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>think</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>297.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>say</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>america</td>\n",
       "      <td>NaN</td>\n",
       "      <td>388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>make</td>\n",
       "      <td>NaN</td>\n",
       "      <td>379.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>work</td>\n",
       "      <td>NaN</td>\n",
       "      <td>341.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>trump</td>\n",
       "      <td>NaN</td>\n",
       "      <td>335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>president</td>\n",
       "      <td>NaN</td>\n",
       "      <td>334.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>us</td>\n",
       "      <td>NaN</td>\n",
       "      <td>314.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>got</td>\n",
       "      <td>NaN</td>\n",
       "      <td>283.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>together</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>donald</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>well</td>\n",
       "      <td>NaN</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Word  frequency_trump  frequency_clinton\n",
       "0       going           5186.0              553.0\n",
       "1      people           3155.0              669.0\n",
       "2        know           2284.0              622.0\n",
       "3     country           1848.0              338.0\n",
       "4        dont           1772.0                NaN\n",
       "5       great           1729.0                NaN\n",
       "6        said           1586.0              293.0\n",
       "7       right           1515.0                NaN\n",
       "8         one           1504.0              272.0\n",
       "9      theyre           1462.0                NaN\n",
       "10    hillary           1460.0                NaN\n",
       "11        get           1381.0              398.0\n",
       "12       want           1360.0              491.0\n",
       "13       like           1344.0                NaN\n",
       "14      thats           1265.0              272.0\n",
       "15       jobs           1253.0                NaN\n",
       "16         im           1160.0                NaN\n",
       "17    clinton           1142.0                NaN\n",
       "18      think           1070.0              297.0\n",
       "19        say           1070.0                NaN\n",
       "20    america              NaN              388.0\n",
       "21       make              NaN              379.0\n",
       "22       work              NaN              341.0\n",
       "23      trump              NaN              335.0\n",
       "24  president              NaN              334.0\n",
       "25         us              NaN              314.0\n",
       "26        got              NaN              283.0\n",
       "27   together              NaN              257.0\n",
       "28     donald              NaN              256.0\n",
       "29       well              NaN              255.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top 20 words for both candidates in one dataframe\n",
    "top20words = pd.merge(top20trump, top20clinton, on='Word', how='outer')\n",
    "top20words.columns = ['Word', 'frequency_trump', 'frequency_clinton']\n",
    "top20words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3AAAANbCAYAAAADgX0iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3XuQV/V9//HXwrIkXZZEWzupFxIwksS2NFyKzFgx2E5x\nnDo1tCGBDjImamKrLSRaMPGC0anQKEzUwYh1Rovh1sp02lx6kTrSqhC7NXWkxVpqTdRaUKuwqyyX\n/f7++I3bEAk3d1ne6+Pxl5w93/P5nN3vXp5+zvd8mxqNRiMAAAAc8wb19wQAAAA4NAIOAACgCAEH\nAABQhIADAAAoQsABAAAUIeAAAACKEHAAAABFCDgAAIAiBBwAAEARzf09AQAAqG7Pnj3p7u7u72lQ\nzKBBg9LcfHhJZgUOAADegR07dmTXrl39PQ0K2rVrV3bs2HFYj7ECBwAAR2jPnj0ZPHhwfuqnfqq/\np0JBLS0teeONN7Jnz55DXomzAgcAAEeou7v7sC+Bgx81ePDgw7r8VsABAAD0k6ampsPa3/8uAACA\nXnTfhu29erzZk4b36vGORTOve6hXj7fiq1N69XjHEgEHAADFLVy4MJs2bcq2bduyc+fOnHLKKTnu\nuONy22239ffUjmnPPPNMvva1r+XNN9/MG2+8kbPPPjsTJ07M6tWrs2TJklx++eW54447fuLjV69e\nnWnTpmXIkCFHbc4CDgAAips/f36SZO3atfnP//zPXHnllf08o2Pf9u3b88UvfjG33357PvShD2Xv\n3r35gz/4g5xwwgk9+xwo3pLkrrvuygUXXNDXU92HgAMAgAFo48aNueWWWzJkyJBMnz49t912W777\n3e9m6NChueWWWzJq1KicdNJJWbZsWYYMGZKXXnopn/nMZ7Jhw4Zs3rw5F154YWbOnJnzzjsvEyZM\nyDPPPJP3ve99Wbx48YC46+a6detyxhln5EMf+lCS/38zkUWLFuWJJ57I9773vSTJmWeemUceeSSz\nZs3KRz/60TzzzDPp6OjI17/+9Tz66KPZtm1b5s6dm6VLl2bhwoVpb29PkvzGb/xGZs+enfnz56el\npSUvvPBCtm7dmoULF+bnf/7n39G83cQEAAAGqK6urqxYseKAq0QvvfRSbr/99ixYsCB33nln/viP\n/zh33313Vq9enSTZuXNnzj///KxcuTKjRo3q2V7d1q1bc8opp+yzrbW19SdeDjlmzJjce++9OfPM\nM/Ptb387n/rUp3LCCSdkyZIleeihh/L8889nzZo1WbFiRb71rW/l6aefTpKceOKJueeeezJr1qxe\n+dwJOAAAGKBGjhy53+2NRqPnv0877bQMGTIkbW1tGTFiRFpaWvK+970vXV1dSZLm5ub88i//cpJk\n3LhxefbZZ/t+4kfBiSeemJdeemmfbT/84Q/z+OOP73f/008/PUnygQ98oOdz85YtW7ZkwoQJaWpq\nypAhQ/JLv/RL2bJlS5LkYx/7WM/jeuMN3wUcAAAMUIMG/d+f+y0tLdm6dWsajUY2b97cs/1gt7Hf\ns2dPz/7t7e358Ic/3DeTPcqmTJmSf/iHf8gPfvCDJMnu3buzcOHCHHfccYd8jKampnR3d+fUU0/t\nuXxy9+7deeKJJ/LBD36wZ5/e5DVwAADQi47V2/5ffPHFufTSS3PSSSdl+PDDm+Pdd9+dF198MSee\neGLmzp3b63Prj9v+Dxs2LAsXLsw111yTRqORzs7OTJkyJaeeemr+6Z/+6ZCOMWHChFx66aX50z/9\n03zve9/Lpz/96ezevTvnnnvuO36t20/S1PjR9VMAAOCQvXVJXEtLSz/PpO+cc845PTc/ofcd7nPI\nJZQAAABFWIEDAIAj9G5YgaNvdXV1pampyQocAAD0tUGDBmXPnj39PQ0K27t37z43mzkYNzEBAIAj\n1NzcnDfffDNvvPFGBg8e3Ot3HGTgajQa2bt3b/bu3Zvm5kPPMpdQAgDAO7Rnz550d3f39zQoZtCg\nQYcVb4mAAwAAKMNr4AAAAIoQcAAAAEUIOAAAgCIEHAAAQBECDgAAoAgBBwAAUISAAwAAKELAAQAA\nFCHgAAAAihBwAAAARQg4AACAIgQcAABAEQIOAACgCAEHAABQhIADAAAoorm/J7A/923Yfsj7zp40\nvA9nAgAAcOywAgcAAFCEgAMAAChCwAEAABQh4AAAAIoQcAAAAEUIOAAAgCIEHAAAQBECDgAAoAgB\nBwAAUISAAwAAKELAAQAAFCHgAAAAihBwAAAARQg4AACAIgQcAABAEQIOAACgCAEHAABQhIADAAAo\nQsABAAAUIeAAAACKEHAAAABFCDgAAIAiBBwAAEARAg4AAKCI5kPZ6ZOf/GSGDRuWJDn55JPzhS98\nIfPnz09TU1NOO+20XH/99Rk0aFDWrFmTVatWpbm5OZdddlmmTJmSnTt35qqrrsorr7yS1tbWLFq0\nKMcff3yfnhQAAMBAdNCA6+rqSqPRyPLly3u2feELX8icOXNyxhln5Lrrrsu6devy8Y9/PMuXL88D\nDzyQrq6uzJw5M2eeeWZWrlyZ0aNH54orrsi3v/3tLF26NNdcc02fnhQAAMBAdNBLKDdv3pw333wz\nn/3sZ3PhhRfm+9//fjZt2pSJEycmSSZPnpxHH300Tz75ZMaOHZuWlpa0tbVlxIgR2bx5c9rb23PW\nWWf17PvYY4/17RkBAAAMUAddgXvPe96Tz33uc/nUpz6V//qv/8oll1ySRqORpqamJElra2t27NiR\njo6OtLW19TyutbU1HR0d+2x/a9/e1N7e3qvHAwAA6G/jx4/f7/aDBtzIkSPzwQ9+ME1NTRk5cmTe\n//73Z9OmTT0f7+zszPDhwzNs2LB0dnbus72trW2f7W/t25t+0okBAAAMNAe9hPLP//zPs3DhwiTJ\n//zP/6SjoyNnnnlmNm7cmCRZv359JkyYkDFjxqS9vT1dXV3ZsWNHtmzZktGjR2fcuHF5+OGHe/YV\nXAAAAEemqdFoNA60w65du3L11VfnxRdfTFNTU6688socd9xxufbaa7N79+6MGjUqN910UwYPHpw1\na9Zk9erVaTQa+fznP5+pU6fmzTffzLx587Jt27YMGTIkt956a0444YQDTuq+DdsP+QRmT+rdFT0A\nAIBj1UEDrj8IOAAAgLfzRt4AAABFCDgAAIAiBBwAAEARAg4AAKAIAQcAAFCEgAMAAChCwAEAABQh\n4AAAAIoQcAAAAEUIOAAAgCIEHAAAQBECDgAAoAgBBwAAUISAAwAAKELAAQAAFCHgAAAAihBwAAAA\nRQg4AACAIgQcAABAEQIOAACgCAEHAABQhIADAAAoQsABAAAUIeAAAACKEHAAAABFCDgAAIAiBBwA\nAEARAg4AAKAIAQcAAFCEgAMAAChCwAEAABQh4AAAAIoQcAAAAEUIOAAAgCIEHAAAQBECDgAAoAgB\nBwAAUISAAwAAKELAAQAAFCHgAAAAihBwAAAARQg4AACAIgQcAABAEQIOAACgCAEHAABQhIADAAAo\nQsABAAAUIeAAAACKEHAAAABFCDgAAIAiBBwAAEARAg4AAKAIAQcAAFCEgAMAAChCwAEAABQh4AAA\nAIoQcAAAAEUIOAAAgCIEHAAAQBECDgAAoAgBBwAAUISAAwAAKELAAQAAFCHgAAAAihBwAAAARQg4\nAACAIgQcAABAEQIOAACgCAEHAABQhIADAAAoQsABAAAUIeAAAACKEHAAAABFCDgAAIAiBBwAAEAR\nAg4AAKAIAQcAAFCEgAMAAChCwAEAABQh4AAAAIoQcAAAAEUIOAAAgCIEHAAAQBECDgAAoAgBBwAA\nUISAAwAAKELAAQAAFCHgAAAAihBwAAAARQg4AACAIgQcAABAEQIOAACgCAEHAABQhIADAAAoQsAB\nAAAUIeAAAACKEHAAAABFCDgAAIAiBBwAAEARAg4AAKAIAQcAAFCEgAMAAChCwAEAABQh4AAAAIoQ\ncAAAAEUIOAAAgCIEHAAAQBECDgAAoAgBBwAAUISAAwAAKELAAQAAFCHgAAAAihBwAAAARQg4AACA\nIgQcAABAEQIOAACgCAEHAABQhIADAAAoQsABAAAUIeAAAACKEHAAAABFCDgAAIAiBBwAAEARAg4A\nAKAIAQcAAFCEgAMAAChCwAEAABQh4AAAAIoQcAAAAEUIOAAAgCIEHAAAQBECDgAAoAgBBwAAUISA\nAwAAKELAAQAAFCHgAAAAihBwAAAARQg4AACAIgQcAABAEQIOAACgCAEHAABQhIADAAAo4pAC7pVX\nXsnZZ5+dLVu25LnnnsuMGTMyc+bMXH/99enu7k6SrFmzJtOmTcv06dPz0EMPJUl27tyZK664IjNn\nzswll1ySV199te/OBAAAYIA7aMDt3r071113Xd7znvckSW6++ebMmTMnK1asSKPRyLp167Jt27Ys\nX748q1atyj333JPFixdn165dWblyZUaPHp0VK1bkggsuyNKlS/v8hAAAAAaqgwbcokWL8pnPfCY/\n+7M/myTZtGlTJk6cmCSZPHlyHn300Tz55JMZO3ZsWlpa0tbWlhEjRmTz5s1pb2/PWWed1bPvY489\n1oenAgAAMLA1H+iDa9euzfHHH5+zzjory5YtS5I0Go00NTUlSVpbW7Njx450dHSkra2t53Gtra3p\n6OjYZ/tb+/a29vb2Xj8mAABAfxo/fvx+tx8w4B544IE0NTXlsccey7/9279l3rx5+7yOrbOzM8OH\nD8+wYcPS2dm5z/a2trZ9tr+1b2/7SScGAAAw0BzwEspvfvObuf/++7N8+fJ87GMfy6JFizJ58uRs\n3LgxSbJ+/fpMmDAhY8aMSXt7e7q6urJjx45s2bIlo0ePzrhx4/Lwww/37Cu2AAAAjtwBV+D2Z968\nebn22muzePHijBo1KlOnTs3gwYMza9aszJw5M41GI3Pnzs3QoUMzY8aMzJs3LzNmzMiQIUNy6623\n9sU5AAAAvCs0NRqNRn9P4sfdt2H7Ie87e1LvX5YJAABwLPJG3gAAAEUIOAAAgCIEHAAAQBECDgAA\noAgBBwAAUISAAwAAKELAAQAAFCHgAAAAihBwAAAARQg4AACAIgQcAABAEQIOAACgCAEHAABQhIAD\nAAAoQsABAAAUIeAAAACKEHAAAABFCDgAAIAiBBwAAEARAg4AAKAIAQcAAFCEgAMAAChCwAEAABQh\n4AAAAIoQcAAAAEUIOAAAgCIEHAAAQBECDgAAoAgBBwAAUISAAwAAKELAAQAAFCHgAAAAihBwAAAA\nRQg4AACAIgQcAABAEQIOAACgCAEHAABQhIADAAAoQsABAAAUIeAAAACKEHAAAABFCDgAAIAiBBwA\nAEARAg4AAKAIAQcAAFCEgAMAAChCwAEAABQh4AAAAIoQcAAAAEUIOAAAgCIEHAAAQBECDgAAoAgB\nBwAAUISAAwAAKELAAQAAFCHgAAAAihBwAAAARQg4AACAIgQcAABAEQIOAACgCAEHAABQhIADAAAo\nQsABAAAUIeAAAACKEHAAAABFCDgAAIAiBBwAAEARAg4AAKAIAQcAAFCEgAMAAChCwAEAABQh4AAA\nAIoQcAAAAEUIOAAAgCIEHAAAQBECDgAAoAgBBwAAUISAAwAAKELAAQAAFCHgAAAAihBwAAAARQg4\nAACAIgQcAABAEQIOAACgCAEHAABQhIADAAAoQsABAAAUIeAAAACKEHAAAABFCDgAAIAiBBwAAEAR\nAg4AAKAIAQcAAFCEgAMAAChCwAEAABQh4AAAAIoQcAAAAEUIOAAAgCIEHAAAQBECDgAAoAgBBwAA\nUISAAwAAKELAAQAAFCHgAAAAihBwAAAARQg4AACAIgQcAABAEQIOAACgCAEHAABQhIADAAAoQsAB\nAAAUIeAAAACKEHAAAABFCDgAAIAiBBwAAEARAg4AAKAIAQcAAFCEgAMAAChCwAEAABQh4AAAAIoQ\ncAAAAEU09/cE+sJ9G7b32bFnTxreZ8cGAAA4ECtwAAAARQg4AACAIgQcAABAEQIOAACgCAEHAABQ\nhIADAAAoQsABAAAUIeAAAACKEHAAAABFCDgAAIAiBBwAAEARAg4AAKAIAQcAAFCEgAMAAChCwAEA\nABQh4AAAAIoQcAAAAEUIOAAAgCIEHAAAQBECDgAAoIjmg+2wd+/eXHPNNXn22WfT1NSUG264IUOH\nDs38+fPT1NSU0047Lddff30GDRqUNWvWZNWqVWlubs5ll12WKVOmZOfOnbnqqqvyyiuvpLW1NYsW\nLcrxxx9/NM4NAABgQDnoCtxDDz2UJFm1alXmzJmTJUuW5Oabb86cOXOyYsWKNBqNrFu3Ltu2bcvy\n5cuzatWq3HPPPVm8eHF27dqVlStXZvTo0VmxYkUuuOCCLF26tM9PCgAAYCA66Arcr/3ar+UTn/hE\nkuTFF1/M8OHD8+ijj2bixIlJksmTJ+eRRx7JoEGDMnbs2LS0tKSlpSUjRozI5s2b097enosvvrhn\nXwEHAABwZA4acEnS3NycefPm5e/+7u9y22235ZFHHklTU1OSpLW1NTt27EhHR0fa2tp6HtPa2pqO\njo59tr+1b29qb2/fz9bTenWMg48HAADQe8aPH7/f7YcUcEmyaNGiXHnllZk+fXq6urp6tnd2dmb4\n8OEZNmxYOjs799ne1ta2z/a39u1N+zuxpzZs79UxDjYeAADA0XDQ18D9xV/8Re66664kyXvf+940\nNTXlF37hF7Jx48Ykyfr16zNhwoSMGTMm7e3t6erqyo4dO7Jly5aMHj0648aNy8MPP9yzrwACAAA4\nMk2NRqNxoB3eeOONXH311Xn55ZezZ8+eXHLJJTn11FNz7bXXZvfu3Rk1alRuuummDB48OGvWrMnq\n1avTaDTy+c9/PlOnTs2bb76ZefPmZdu2bRkyZEhuvfXWnHDCCQec1H2HsYI2e9LbV/QO5/GHa3/j\nAQAAHA0HDbj+IOAAAADezht5AwAAFCHgAAAAihBwAAAARQg4AACAIgQcAABAEQIOAACgCAEHAABQ\nhIADAAAoQsABAAAUIeAAAACKEHAAAABFCDgAAIAiBBwAAEARAg4AAKAIAQcAAFCEgAMAAChCwAEA\nABQh4AAAAIoQcAAAAEUIOAAAgCIEHAAAQBECDgAAoAgBBwAAUISAAwAAKELAAQAAFCHgAAAAihBw\nAAAARQg4AACAIgQcAABAEQIOAACgCAEHAABQhIADAAAoQsABAAAUIeAAAACKEHAAAABFCDgAAIAi\nBBwAAEARAg4AAKAIAQcAAFCEgAMAAChCwAEAABQh4AAAAIoQcAAAAEUIOAAAgCIEHAAAQBECDgAA\noAgBBwAAUISAAwAAKELAAQAAFCHgAAAAihBwAAAARQg4AACAIgQcAABAEQIOAACgCAEHAABQhIAD\nAAAoQsABAAAUIeAAAACKEHAAAABFCDgAAIAiBBwAAEARAg4AAKAIAQcAAFCEgAMAAChCwAEAABQh\n4AAAAIoQcAAAAEUIOAAAgCIEHAAAQBECDgAAoAgBBwAAUISAAwAAKELAAQAAFCHgAAAAihBwAAAA\nRQg4AACAIgQcAABAEQIOAACgCAEHAABQhIADAAAoQsABAAAUIeAAAACKEHAAAABFCDgAAIAiBBwA\nAEARAg4AAKAIAQcAAFCEgAMAAChCwAEAABQh4AAAAIoQcAAAAEUIOAAAgCIEHAAAQBECDgAAoAgB\nBwAAUISAAwAAKELAAQAAFCHgAAAAihBwAAAARQg4AACAIgQcAABAEQIOAACgiOb+nsBAcN+G7X12\n7NmThvfZsQEAgFqswAEAABQh4AAAAIoQcAAAAEUIOAAAgCIEHAAAQBECDgAAoAgBBwAAUISAAwAA\nKELAAQAAFCHgAAAAihBwAAAARQg4AACAIgQcAABAEQIOAACgCAEHAABQhIADAAAoQsABAAAUIeAA\nAACKEHAAAABFCDgAAIAiBBwAAEARAg4AAKAIAQcAAFCEgAMAAChCwAEAABQh4AAAAIoQcAAAAEUI\nOAAAgCIEHAAAQBECDgAAoAgBBwAAUISAAwAAKELAAQAAFCHgAAAAihBwAAAARQg4AACAIgQcAABA\nEQIOAACgCAEHAABQRPOBPrh79+58+ctfzgsvvJBdu3blsssuy4c//OHMnz8/TU1NOe2003L99ddn\n0KBBWbNmTVatWpXm5uZcdtllmTJlSnbu3Jmrrroqr7zySlpbW7No0aIcf/zxR+vcAAAABpQDrsD9\n5V/+Zd7//vdnxYoV+ZM/+ZPceOONufnmmzNnzpysWLEijUYj69aty7Zt27J8+fKsWrUq99xzTxYv\nXpxdu3Zl5cqVGT16dFasWJELLrggS5cuPVrnBQAAMOAccAXu3HPPzdSpU5MkjUYjgwcPzqZNmzJx\n4sQkyeTJk/PII49k0KBBGTt2bFpaWtLS0pIRI0Zk8+bNaW9vz8UXX9yzb18EXHt7+362ntbr4xxb\n4wEAAAPZ+PHj97v9gAHX2tqaJOno6Mjv//7vZ86cOVm0aFGampp6Pr5jx450dHSkra1tn8d1dHTs\ns/2tfXvb/k7sqQ3be32cY2k8AADg3emgNzH57//+71x44YX5zd/8zZx//vkZNOj/HtLZ2Znhw4dn\n2LBh6ezs3Gd7W1vbPtvf2hcAAIAjc8CAe/nll/PZz342V111VX77t387SXL66adn48aNSZL169dn\nwoQJGTNmTNrb29PV1ZUdO3Zky5YtGT16dMaNG5eHH364Z1+rSQAAAEfugJdQfuMb38j27duzdOnS\nntevfeUrX8lNN92UxYsXZ9SoUZk6dWoGDx6cWbNmZebMmWk0Gpk7d26GDh2aGTNmZN68eZkxY0aG\nDBmSW2+99aicFAAAwEDU1Gg0Gv09iR9332G8pmz2pLdflnk4jz9cx8J4AADAu5M38gYAAChCwAEA\nABQh4AAAAIoQcAAAAEUIOAAAgCIEHAAAQBECDgAAoAgBBwAAUISAAwAAKELAAQAAFCHgAAAAihBw\nAAAARQg4AACAIgQcAABAEQIOAACgCAEHAABQhIADAAAoorm/J8Dhu2/D9j479uxJw/vs2AAAwDtj\nBQ4AAKAIAQcAAFCEgAMAAChCwAEAABQh4AAAAIoQcAAAAEUIOAAAgCIEHAAAQBECDgAAoAgBBwAA\nUERzf0+AY999G7b3yXFnTxreJ8cFAICBygocAABAEQIOAACgCAEHAABQhIADAAAoQsABAAAUIeAA\nAACK8DYCHHO8bQEAAOyfFTgAAIAiBBwAAEARAg4AAKAIAQcAAFCEgAMAAChCwAEAABQh4AAAAIoQ\ncAAAAEUIOAAAgCIEHAAAQBECDgAAoAgBBwAAUISAAwAAKELAAQAAFCHgAAAAihBwAAAARQg4AACA\nIgQcAABAEQIOAACgCAEHAABQRHN/TwD6230btvfJcWdPGt4nxwUA4N3LChwAAEARAg4AAKAIAQcA\nAFCEgAMAAChCwAEAABQh4AAAAIoQcAAAAEUIOAAAgCIEHAAAQBECDgAAoIjm/p4AvNvct2F7nxx3\n9qThfXJcAACOHVbgAAAAirACBwOcFT8AgIHDChwAAEARAg4AAKAIAQcAAFCEgAMAAChCwAEAABTh\nLpRArzrad710l00A4N3EChwAAEARAg4AAKAIAQcAAFCEgAMAAChCwAEAABQh4AAAAIoQcAAAAEUI\nOAAAgCIEHAAAQBECDgAAoAgBBwAAUERzf08AoIr7Nmzvs2PPnjS8z44NAAwcVuAAAACKEHAAAABF\nuIQS4Bjlkk0A4MdZgQMAACjCChwASaz4AUAFVuAAAACKEHAAAABFCDgAAIAiBBwAAEARAg4AAKAI\nAQcAAFCEgAMAAChCwAEAABQh4AAAAIoQcAAAAEUIOAAAgCKa+3sCALw73bdhe58cd/ak4X1yXAA4\nFliBAwAAKMIKHADvClb8ABgIrMABAAAUIeAAAACKEHAAAABFCDgAAIAiBBwAAEARAg4AAKAIAQcA\nAFCEgAMAAChCwAEAABQh4AAAAIoQcAAAAEUIOAAAgCIEHAAAQBHN/T0BABiI7tuwvU+OO3vS8D45\nLgA1WIEDAAAoQsABAAAU4RJKABgAXLIJ8O5gBQ4AAKAIAQcAAFCEgAMAAChCwAEAABQh4AAAAIoQ\ncAAAAEUIOAAAgCIEHAAAQBECDgAAoAgBBwAAUERzf08AAKjnvg3b++S4sycNPybGAzhWWYEDAAAo\nQsABAAAUIeAAAACKEHAAAABFCDgAAIAiBBwAAEARhxRw//Iv/5JZs2YlSZ577rnMmDEjM2fOzPXX\nX5/u7u4kyZo1azJt2rRMnz49Dz30UJJk586dueKKKzJz5sxccsklefXVV/voNAAAAAa+gwbc3Xff\nnWuuuSZdXV1Jkptvvjlz5szJihUr0mg0sm7dumzbti3Lly/PqlWrcs8992Tx4sXZtWtXVq5cmdGj\nR2fFihW54IILsnTp0j4/IQAAgIHqoAE3YsSI3H777T3/3rRpUyZOnJgkmTx5ch599NE8+eSTGTt2\nbFpaWtLW1pYRI0Zk8+bNaW9vz1lnndWz72OPPdZHpwEAADDwNR9sh6lTp+b555/v+Xej0UhTU1OS\npLW1NTt27EhHR0fa2tp69mltbU1HR8c+29/at7e1t7fvZ+tpvT6O8Y7WWMYz3rE83sD43hvo4x0b\nzxXj1R8PoH+NHz9+v9sPGnA/btCg/1u06+zszPDhwzNs2LB0dnbus72trW2f7W/t29v2d2JPbdje\n6+MY7+iMZTzjHcvjDZTvvYE+3rHwXDFe/fEAjlWHfRfK008/PRs3bkySrF+/PhMmTMiYMWPS3t6e\nrq6u7NixI1u2bMno0aMzbty4PPzwwz37+iEJAABw5A57BW7evHm59tprs3jx4owaNSpTp07N4MGD\nM2vWrMycOTONRiNz587N0KFDM2PGjMybNy8zZszIkCFDcuutt/bFOQAAALwrHFLAnXzyyVmzZk2S\nZOTIkbn//vvfts/06dMzffr0fba9973vzW233dYL0wQAAMAbeQMAABQh4AAAAIoQcAAAAEUIOAAA\ngCIEHADX8Ox5AAAgAElEQVQAQBECDgAAoAgBBwAAUISAAwAAKELAAQAAFCHgAAAAihBwAAAARQg4\nAACAIgQcAABAEQIOAACgCAEHAABQhIADAAAoQsABAAAUIeAAAACKEHAAAABFCDgAAIAiBBwAAEAR\nAg4AAKAIAQcAAFCEgAMAAChCwAEAABQh4AAAAIoQcAAAAEUIOAAAgCIEHAAAQBECDgAAoAgBBwAA\nUISAAwAAKELAAQAAFCHgAAAAihBwAAAARQg4AACAIgQcAABAEQIOAACgCAEHAABQhIADAAAoQsAB\nAAAUIeAAAACKEHAAAABFCDgAAIAiBBwAAEARzf09gb7wN99p77Njz540pc+ODQAAcCBW4AAAAIoQ\ncAAAAEUIOAAAgCIEHAAAQBECDgAAoAgBBwAAUMSAfBuBo83bFgAAAEeDFTgAAIAiBBwAAEARAg4A\nAKAIAQcAAFCEgAMAAChCwAEAABQh4AAAAIoQcAAAAEUIOAAAgCKa+3sC+/M332k/5H1nT5rShzMB\nAAA4dliBAwAAKELAAQAAFCHgAAAAihBwAAAARQg4AACAIgQcAABAEQIOAACgCAEHAABQxDH5Rt4A\nJH/znfY+O/bsSVP67NgAQN+xAgcAAFCEgAMAAChCwAEAABQh4AAAAIoQcAAAAEUIOAAAgCIEHAAA\nQBECDgAAoAgBBwAAUISAAwAAKELAAQAAFCHgAAAAihBwAAAARTT39wQAqvib77T32bFnT5rSZ8cG\nAAYOK3AAAABFWIEDAPgxM697qE+Ou+KrVtuBd0bAAQD0o76KxUQwwkDkEkoAAIAiBBwAAEARAg4A\nAKAIAQcAAFCEgAMAACjCXSgL8mbCAMCRctdLqE3AAQDQZ452MHoPPwY6l1ACAAAUIeAAAACKcAkl\nAAAcIZdscrRZgQMAACjCChwAcNj66o7I7oYMcGACjnc9f4QAAFCFgAMAgCK85g6vgQMAACjCChwM\ncC4R5VjluQkAh88KHAAAQBFW4AAAgP062q+58xq/gxNwAADAu1LFYHQJJQAAQBECDgAAoAgBBwAA\nUISAAwAAKELAAQAAFCHgAAAAihBwAAAARQg4AACAIgQcAABAEQIOAACgCAEHAABQhIADAAAoQsAB\nAAAUIeAAAACKEHAAAABFCDgAAIAiBBwAAEARAg4AAKAIAQcAAFCEgAMAAChCwAEAABQh4AAAAIoQ\ncAAAAEUIOAAAgCIEHAAAQBECDgAAoAgBBwAAUISAAwAAKELAAQAAFCHgAAAAihBwAAAARQg4AACA\nIgQcAABAEQIOAACgiOa+HqC7uzsLFizI008/nZaWltx000354Ac/2NfDAgAADDh9vgL34IMPZteu\nXVm9enW+9KUvZeHChX09JAAAwIDU5wHX3t6es846K0ny8Y9/PE899VRfDwkAADAgNTUajUZfDvCV\nr3wlv/7rv56zzz47SfKJT3wiDz74YJqb+/zqTQAAgAGlz1fghg0bls7Ozp5/d3d3izcAAIAj0OcB\nN27cuKxfvz5J8v3vfz+jR4/u6yEBAAAGpD6/hPKtu1D++7//exqNRv7oj/4op556al8OCQAAMCD1\necABAADQO7yRNwAAQBECDgAAoAgBBwAAUMQxFXDbtm3LggUL+nsaPTZu3Ji5c+cedL+1a9fmlltu\nOQoz6h2vvfZa/uqv/uodHaOrqyvnnHPOUR/3SNx///29erxly5blySef3GfbkXw+ftTll1/+Ez/2\n/PPPZ/r06W/b/uKLL+bv//7vj3jM3tTV1ZU/+7M/y+23356VK1celTH39303d+7c7Nq1K/Pnz8/6\n9euPue/N3n4uHo7HH388mzdvPuzHrV27Ntddd13Pz+ZzzjknXV1dvTavI3nuvPWYI7V+/fqsXr16\nvx87Gs/hA43/Tr31nD+U36e98Xw82NfvSH62DQRr167NunXr+nyM/vr5djhfu3f6/dqX3vqd8aPW\nr1+f+fPnH/axjvRn7NG2evXq7N69+23be/Pr9PTTT+fxxx9Pcvi/M97p31M/an9jH+nXd3/682+N\nYyrgTjjhhGMq4Aaqp59+ul/+8O+vce+8885ePd6ll16aMWPG9Oox77jjjsN+zIYNG/LP//zPvTqP\nI7Vt27Zj4hf0kiVL0tLS0t/T+Il6+7l4OB544IFs3br1iB47fPjwPvvZfCTPnXf6fJs8eXI+/elP\nH/Hj36mjMf6h/D7tjefjwb4WR/KzbSCYNm1afvVXf7W/p3FMOFZ+P+xPb/7OeCc/Y4+mu+66K93d\n3W/b3ptfp7/927/Nf/zHf/TKsdi/o/KO2jt37swf/uEfZuvWrfm5n/u5PP7441m2bFluvPHGDB48\nOEOHDs2NN96Y7u7ufPGLX8yaNWty/vnnZ+LEiXn66afT1NSUpUuXZtiwYbnhhhvy1FNP5Wd+5mfy\nwgsv5M4778zJJ5+ctWvX5sEHH0xnZ2f+93//N7/3e7+X4447LkuWLMngwYNzyimn5Ktf/WqS5Oqr\nr87zzz+fvXv35qKLLsp5552XWbNmZeTIkXn22WfTaDSyZMmSfc7hu9/9bu69994MGjQo48ePz5VX\nXvm283z11Vfzu7/7u/mt3/qt/OM//mN27tyZH/zgB7nkkksybdq0/Ou//uvbzvnee+/NuHHjcu65\n5+Zzn/tcfuVXfiUXXXRRrrnmmkybNi2nn356rr766rz44ovZvXt3vvzlL2fVqlX7nf+CBQty6qmn\nZuXKlXn55ZfzyU9+Ml/60pfygQ98ID/84Q/zi7/4i7nhhhvyjW98I5s3b87q1avzxBNP5LXXXstr\nr72Wj3zkIxk9enR+53d+J6+//nouuuiirF27tuf8Ojs7c+WVV2b79u0ZMWJEkuz3nLq7uw867oH+\neNnf82XkyJE5/vjj8/rrr2fZsmVZsGBBnnvuuXR3d2fOnDk544wz8td//df55je/mT179qSpqSl3\n3HFHVq9enddffz0LFiw46B8zzz77bK6++uo0Nzenu7s7X/va17J06dK89NJL2bp1a84555zMnTs3\n8+fPz3nnndfzPPjRz8fhWLt2bR544IF0d3fn2WefzYYNG/Lkk0/mhhtuSGtra376p386Q4cOzeWX\nX97z3Nq2bVs+8pGP5IYbbsiyZcuyc+fOjB079pD/UNi9e/fbnv8rV67MRz/60TzzzDPp6OjI17/+\n9Zx00klZvnx5vvWtb6WpqSnnnXdeLrzw/7X35nE1p////6NStJJqohGjZJksESpZKktSilSKyNjG\n+y3LNNKKIltRpqxJg8J7UAzDvMlOJMuQbGXLyUibdh2dc56/P/qd17dT5+TkM8Pb+33dbze3W17n\n9bqu5/N5PZ/Xdb2u5XVNl5nu9u3b8eTJE2RlZWHo0KH497//jbKyMixatAh2dnZS48fT0xOrVq2C\niYkJLl68iPPnz0NHRwd//PEHampqsHr1aly9erVZGe7evYuZM2eitLQUXl5e2LFjB37//XepMm7c\nuBHZ2dkoKytDz549sXbtWsTFxXH5OTg4oKCgAAEBARAKhZgwYQIOHz6M1q1bN2tTaf66a9cuRERE\nAADatWuHNWvWIDk5WW5fbIirqyt27twJLS0tWFhYICkpCaamppg4cSKGDh0qVaf8/HyUlJTgzz//\nRFBQELS1tXH58mXcv38f3bp1g4GBgdz5A8CrV6/g4eGBgwcPctcOHDiA9PR0REdH486dO03qWmVl\nZbnS/pDvJCcn4/Tp03j37h20tbWxefNm7pnNmzfDysoK69evR6tWraCqqoqffvoJGhoazeaZmpqK\nZ8+eoX379jhx4gRatWqFgQMHwt/fHwBw5swZ/P7776itrUVoaCj69u2LoKAg5OXloba2FtOnT8eE\nCRNaZMPG+V++fBn5+fno2LEj8vPz4ejoiNzcXDx48AA2Njbw8/OTK63a2lqJNsLe3h5A/QxJc+1p\nQ38MCQmR2S5Kqxsa8qHys7a2Rnp6utS0xAiFQgQGBsLExARz586VS2956utFixbB3t4ehw4dQrt2\n7bB//35UV1djzpw5XDpVVVUICQlBZWUlCgsLMWXKFPz+++/o0aMHcnNzoaamhoEDB+LKlSuoqKhA\nYmIi1NTUsGLFiiZtkJOTE7755hsoKyvDyMgIurq6XD2XlZWFuro6LFiwALa2tli+fLmErF26dMH5\n8+dRW1uLoqIiTJ8+HWfPnkVubi6WLl2KgoKCJnEgRtw+LFq0CAMHDpQqmzSaq1scHBxw6tQpidho\nWF+uXr1a7rIT+0jPnj0xZMgQ7vmgoCCuTvHw8EB0dDSOHDmCvLw8vH37FmVlZZg6dSpOnz6N58+f\nY/369dDV1cX06dPB5/NRU1MDVVVVrFixAnFxcZztV65ciZCQELx9+xYAEBoaih49ekiNYXH7lJ+f\nj+DgYKiqqkJVVRVt27YFIL3v15I6VlzXLFmyBHw+Hw4ODpg1axaOHj0KRUVF9OnTB6GhoXL5fHPI\n289OT09HUVERfvjhB2zdulVqOW3evBn37t1DVVUVhEIhFi1aBCsrK5w/fx6xsbHQ0NBA27Zt0aNH\nDyxYsAAbN27EzZs3IRKJMGPGDAwYMABHjhyBsrIyTE1NAQBhYWHIz88HUD+o0ziG5s2bh3/961+4\nevUq2rdvj7dv37aof1lQUICwsDDw+XwUFRVh8eLFGDVqFKfb06dPpZZvY5qLiQkTJuDkyZNy9Yk+\nCfQJ2L17N61fv56IiJ48eUI9e/akiRMn0oMHD4iIKC0tjRYsWEA8Ho/c3d2JiMjW1pZu3bpFRER+\nfn7022+/UVpaGi1atIiIiEpKSsjc3Jx4PB4REaWkpNCMGTNIKBRSUVER2djYkJ2dHRUXFxMRUUxM\nDP3yyy+UlJREq1evJiKiyspKGj16NJWUlJC3tzcdOXKEiIiSk5Np1apVlJGRQYsXL6a3b9+Sg4MD\n1dTUEBHRkiVL6MqVK5x+KSkpFBgYSB4eHnTnzh1KSUmhmTNnEhHR8+fPyd7enohIqs6ZmZkUFBRE\n7969Izc3N5ozZw6JRCKaMGECiUQi+vnnnykqKopLa8uWLTLlf/LkCRER7d+/n2JjY4nH49HgwYOp\nsrKSBAIB2djYUGFhIacXEVFAQAD9/PPPRET08uVLcnNz42yQmJgoUY4JCQkUHR1NRER37twhW1tb\nmeX4oXxb6i/e3t50+vRpIiLat28fRUZGEhFRaWkpjRs3joiItm3bxpXRsmXL6NdffyUioiFDhnww\nT7HOq1evpvfv39PVq1fp8ePHdPDgQSIiqq2tpcGDB3M2u3jxolR7tISUlBSaN2+ehIwTJkygnJwc\nIiKKjo6mgIAA4vF4ZGFhQWVlZSQUCjm/TklJ4XxDXqT5v6OjIx07dozLc8eOHZSbm0uenp4kEAhI\nIBDQtGnT6OnTpzLTFcdubGwsBQcHExFRRkYGzZ49W2b8HD58mCvnBQsWUHZ2NsXGxtKqVauIiD4o\ngzjmRSIR8Xg8cnBwIFtbW6qtreXKSGyjyspKio+PJyIioVBIY8eOpYKCAon8xPYQCAR0/vx57vqH\nkOav7u7ulJubS0REBw8e5PxEXl9sSFxcHB05coSuXbtG48ePp/j4eMrNzaX58+fL1Ck0NJSIiK5c\nucLVRWKbtJSUlBRavHixRN28c+dO8vPzI4FAQCKRiMaMGdOkrpWX5nxHKBRSXFwcCYVCIiKaOXMm\n3bx5U6KtWLduHSUmJpJQKKS0tDR69eqVXDr5+vqSm5sbvX//nkQiEc2fP5/OnTtHsbGxtGzZMiIi\nysnJoQkTJlBlZSWNHDmSSkpKqKSkhIuXj0VsUwsLC6qoqKDCwkLq06cPvX37lmpra8nKykrutBq3\nEeL/f6g9Jfp//thcu9i4bmhMc+XXMA9pafF4PJo4cSItXryYkpOTW2BB+evrn376iUt78uTJVFRU\nJJFOdnY2nTp1ioiICgoKaPTo0eTt7c21HzNnzuSeX7p0KaWlpclsg2xtben+/ftERBQbG0v79++n\n06dPc+1eWVkZxcTEEI/HayJrSkoKfffdd0RE9Ntvv5GbmxuJRCK6du0aff/991LjoHHfg0h2+ygN\nWXVLc7EhrhdbUnYNfaTh82L/JCJyd3cnHo9HsbGxFBISQkREO3bsoIULFxIR0eHDhykiIoJ4PB6Z\nmZmRt7c3vX//niZOnEhDhgyhYcOGcbaPjIykffv2EVF9THh6esqMYXGbMXfuXK5ft2PHDgoICJDZ\ndrWkjm3YTtfW1pKtrS25urrS3bt3ufKqq6tr1n7yIG8/u6HOjRGXybp162j37t1EVB8Ttra2JBAI\nyM7OjosfPz8/io2NpQsXLnD+XVtbS87OzlReXs75vzi/GzducDY6ceJEEz+1srKi6OhosrW1pSNH\njrS4f5menk4ZGRlERHTr1i2aMWOGhK7SylcasmJi4cKFUvsjjfsan5JPMgP39OlTDB8+HABgbGyM\n9u3bo7CwEL169QIADBo0CBs3bmzy3LfffgsA6NixI/h8Pl69egUzMzMAQPv27WFkZCRx/6BBg6Co\nqAhdXV2oqqoiLy8PixcvBlA/OjFkyBBUVFRgyJAhAAANDQ0YGxuDx+MBACwtLQEAAwYMkFjq9/Ll\nS5SWlnKjS9XV1Xj58iWsra25ey5fvgw9PT1uWrpnz56c7OL11dJ0Njc3x+rVq3H9+nWMGTMGp06d\nws2bN2FmZgYFBQU8e/aMs90333yDoqIimfKLoQZH+3Xu3JkbjdbT05O6Drlr164AAENDQ6irq+PJ\nkyc4fvx4k9GZFy9eYMSIEQCAfv36oVWrVjLLUZ58ZSHNXxrKmZOTg1u3bnH70AQCAUpLS6Gjo4OA\ngACoq6vj2bNnnK/Ii5ubG3bu3InZs2dDU1MTvr6+uHfvHjIyMqChodFknbw0e7QUsU5iCgsLYWJi\nAgAwNzfHyZMnAdSXjXjESEdHB+/evWtxXkC9bRv7T3p6OhdrHTp0QHFxMXJycvDnn39ixowZAIDy\n8nLk5eU1iTlpiEfcdHV1uVloafHj4uICV1dXzJo1C2/evIGpqSnOnTsnUc4fkuHbb7+FgoIC9PT0\nUFtbK1Om1q1bo7S0FH5+flBTU0NNTQ23B0Ccn4aGBgYNGoQrV64gNTUV//znP+W2aWN/ffr0KcLD\nwwHUz3p+8803cqUljTFjxmD79u3o2LEjfvjhByQlJYGI4OjoiKysLKk6iWOyQ4cOTfz2r+DatWtQ\nUlKCkpISSkpKUFhY2KSu/Rga+46ioiKUlZU5HQsKCiAQCCSemTdvHrZv3w4fHx/o6+vLvbz54cOH\nsLGx4WYKBw4ciNzcXAD1dRkAmJiYoKioCBoaGggODsayZctQVVUFZ2fnj9KvMYaGhtDU1ISKigp0\ndXXRrl07AICCgoLcaTRuI7S0tFBcXNzkvsbtaUOk1QvidqVx3dAcjctPlgwN03r8+DE0NDRQU1Mj\nn8L/P/LW15MmTYKfnx8GDRoEXV1d6OrqSqSjq6uLPXv24PTp09DQ0OD8S6yLlpYWunXrxv3N5/Nl\ntkFA0zr9+fPnXFvUtm1bLF68GFVVVVJlFcetpqYmjI2NoaCggLZt26Kurk5mHDTue8iSTdyONkRW\n3TJu3DjcunVLamw01O9jyq6xfcQ07LeI/URTU5Ozfdu2bTm/7dixI6ysrKCsrAxzc3OcOXMGRUVF\nEm1HRkYGtxqjvLz8gzH84sULru4YMGAAnj17JrPtAj6ujhXruHbtWiQmJiIyMhJmZmYSun8sH9vP\nlpXW+PHjAQD6+vrQ0NBAQUEBNDQ0uPgZOHAg11e4f/8+pk2bBqDe3169etUkzd69ewP4f3VDYz/l\n8/lc+dnb22Pr1q0t6l/q6elh27ZtOHz4MBQUFJq0E9LKVxqyYsLe3h7r169v0h/5nHySPXDdu3fH\nH3/8AaD+Zejt27f46quvuM2eN27ckNrBadyImZiY4M6dOwDqjffixQuJ3+/fvw8AKC4uBp/PR+fO\nnbF161YkJSVh3rx5sLS0hLGxMW7evAmgfulETk4OOnXqBADIzs4GANy+fZurNACgU6dO6NixIxIT\nE5GUlARvb+8mLwcTJkxAZGQkQkND8e7dO6kNsDSdFRUV0bt3byQkJGDo0KEwNzdHVFQUxowZA6A+\nEO/duwcA4PF4OHHihFT5VVRUUFRUBKB+WaMsGwKAoqKixPrnhvd4eHhg69at0NfXb1LhGxsbc/Z/\n8OABBAKBzHKUJ19ZSPOXhmkaGRnB0dERSUlJ2LlzJ8aOHQtlZWXExsYiJiYGERERaN26NVcpyls5\nnj17Fubm5tizZw/Gjh0LFxcXaGpqYuPGjZg5cyZqa2sl0pJmj5aiqCgZgh06dODWjd+9e5e7/n+x\nZ0Oa8/+GGBkZoVu3bti7dy+SkpLg6uqKHj16NKuHWJbGssqKHzU1NVhYWGD16tUSjanYJvLIIG9H\n99KlS3j9+jWio6Ph5+cnUZYNy8DDwwOHDh1CSUkJNwjzIaT5a9euXbF+/XokJSXB398fNjY2AOT3\nxcbp83g8ZGVlYcSIEaipqcHZs2ehrKwsUydpdlFQUPhLOgoAsHXrVmhpaeHAgQPQ1tZGhw4dmtS1\n8tKc7zx69AhnzpzBpk2bsGzZMohEIhCRxDPHjh3DxIkTkZSUBBMTE4llns3Rq1cvZGVlQSAQgIi4\npdoAuE7F48ePYWBggMLCQty/fx9btmxBfHw8oqKiPireG9OSFzVZNG4joqOj5c5L7A/y1gvSaK78\n5MHU1BTx8fE4duxYiz4AIW99/fXXX0NTUxPbt2+Hm5tbk3QSExNhZmaGDRs2YOzYsXLFiLQ2SPzy\n3bhONzIy4sqnsrISs2bNQmpqqlRZZdmvrq5OahwAkn2PmpqaZmVrjKy6pWvXrjJjo6F+8pZdQx8R\nP9+6dWuUlJRAKBSioqKCW14HfNiPCgsLkZWVBaFQiFu3bkEoFEJHR0ei7ZgxYwaSkpKwadMmODs7\nfzCGjY2NuXpc3Bdsru8nbx3bunVrrm8m7qMePHgQ4eHhSE5OxsOHD7l8/y+0pJ+toKAgte8gLqeG\n9cGbN29QUVEBPT09VFdXcwMV4v6JkZERt9Rwz549cHBwgKGhYZM8GtursZ/27duXGyR4/Phxi/uX\nP/30E1xcXBAVFQULC4sm5SCtfGXZUVpMtLRP9Cn4JDNwbm5uCAwMxNSpU2FgYIDWrVsjIiICq1at\nAhFBSUkJa9as+WA6NjY2uHTpEjw9PaGrq4s2bdpI7LMoLi6Gj48PKisrsWLFCigqKmLu3LkgIqir\nqyMyMhLm5uZYtmwZvLy8wOfz4evrCx0dHQDAkSNHsHv3bqiqqiIyMhI5OTkA6mf7ZsyYgWnTpkEo\nFOLrr7+Gg4NDE/lMTEzg7OyMtWvXcm/pDZGl8+jRoxEUFISePXti6NChOHr0KDcC7OnpieDgYHh7\ne0MoFCIhIQH79u1rIv/06dMRHh4OAwMDfPXVV83asXPnzsjJycHu3bub/DZq1CisXLkSUVFRTX7z\n8vLC0qVL4eXlBSMjIygrK7eoHBvmK80+YqT5S0M8PT0RGhoKb29vVFVVYcqUKdDQ0MCAAQMwefJk\ntGrVClpaWtxmYmNjYyxZsuSDXwjq3bs3AgICsG3bNohEIuzfvx/h4eG4c+cOVFRU0KVLF4kNytLs\n8X9lxYoVCA4OhpqaGpSVlaGvry/z3u7du2Pbtm0wNTWFo6OjXOl7eHg08f+G+xzF9OzZE1ZWVvDy\n8sL79+/Rt2/fZmXR0dFBXV2d1FH35uLHw8MDU6ZMkbonrKUyNEffvn2xdetWTJ06FQoKCjA0NJS6\n2bxfv37Iy8vD1KlT5U5bmr+GhYUhICCA248p3i8iry82ZvDgwcjPz4eioiIGDRqEJ0+eoF+/fti2\nbdsHdWqo24YNG9CpUycYGxu3KH9phIaGwt3dHVZWVggJCWlS18pLc77TpUsXqKqqwtPTE0D9aGth\nYSH69++Puro6brArNDQUqqqqUFRU5PY6f4guXbpgwIAB8PLygkgkgrm5OUaNGoVHjx4hPz8f06dP\nx/v377Fy5Uro6emhqKgInp6eUFRUxMyZMz9qxv3voHEb8d1333GDXh9C7I9r1qyR2S5+iObKT17a\ntGmDFStWICAgAIcOHZLroxLy1tf6+vrw8PBARESE1HbN1tYWEREROHnyJDQ1NaGkpPTBGRVpbVDj\nFzcxI0eOxLVr1+Dl5QWhUIj58+fDwMAAP/74o4SslZWVMvMT7+9sHAdiGvY9li1bJrdsgPS6pWfP\nnnBwcJAaG42Rp+yk+Yienh6sra3h5uYGQ0NDdOnSRaaMjVFSUsLNmzcxaNAgaGhoICIiQqINmTdv\nHkJCQnDw4EFUVVXB19f3gzEcGBiIgIAA7Nq1C+3bt0fr1q3l7vuJkVbHDhs2DAcOHICXlxdMTU2h\nrq6OHj16YMqUKVBXV4e+vj769esnt+6yaEk/e+DAgZg7dy727t0r8TIkLqfKykrk5eXh1KlTqK2t\nxcqVK6GiooJly5Zhzpw50NTUhEgkQpcuXWBnZ4fMzExMmTIFNTU1GDVqFDQ0NNC7d29ERkbKbGsa\nx5C7uzsyMzNRVFSEf/3rXy3uX44dOxaRkZGIj49Hhw4dmtSB0spXFrJi4q/qj/xlfIJlmnTr1i26\nfPkyEdWvRx45cuRHpfPkyRNu7X5paSkNGTKE+Hw+EdH/ef1pwz1k/8vU1NSQq6srt9b+c/BX+cuX\nSHJyMpWUlBBR/T6RuLi4zyzR38vdu3fJ39//c4vBIRQKycPDgyorK+V+5n/ZX79UfvnlF9q0adPn\nFoPxiTh58iQr7/8SeDwejRw58pPvN/pP51O0Q9u3b+f63D/++CP33QjG5+GTDCEaGhrCz88Pmzdv\nhkAgwPLlyz8qnY4dO2LDhg3Ys2cPhEIhlixZ8h/9yfAvjdu3b2PFihWYP39+syN2fzd/lb98iejo\n6Dp5QGsAABIaSURBVGDmzJlQU1ODpqYm1q1b97lF+ttITk7G4cOHsWnTps8tCoD65We+vr5wdXX9\n4FcMG/K/7K9fIhcvXsTevXvZkTX/I0RHR+P69evYvn375xaFwfjb+BTtkLq6Ojw8PNCmTRt8/fXX\nGDdu3F+eB0N+FIj+ok0RDAaDwWAwGAwGg8H4W/mPOsibwWAwGAwGg8FgMBiyYS9wDAaDwWAwGAwG\ng/GFwF7gGAwGg8FgMBgMBuMLgb3AMRiML478/Hz07t0bLi4uEv9ev379uUX7W4mNjcXIkSPx888/\nS1wPCgqSenjqfwL5+fmws7OT+/6goCDY29vjt99++xulap64uDjExcV9lrxdXFykXrezs5M4K6sl\niA/ZbS59MampqQgMDPyofFpKQzt/rN6VlZX45z//2aJ8P2SDhgiFQqxYsQJOTk5wdHSUOH7n+PHj\nGDduHEaPHo19+/ZJPFdXVwcfHx9cv36du/bs2TNMmzYNzs7OmDVrFsrLy1skN4PBYIj5zzjIhsFg\nMFrIV199hV9//fVzi/FJ+fXXX5GQkMAdqivm+vXrmD9//meS6q/lyJEjyMrK+p/9wvDf4dOZmZl/\na/p/BR8rV3l5eYsOAG9pXqmpqSgrK8OxY8dQW1sLNzc3DBo0CLq6uoiJiUFqaipUVFTg6ekJCwsL\ndOvWDc+ePUNwcDAePHjApUNE+Mc//oGQkBAMHz4cGzZsQHx8PPz9/VskO4PBYADsBY7BYPyXERgY\niLKyMuTl5cHf3x+6urpYu3Ytamtroa2tjfDwcBgaGiI7OxvLli0DUH/Y6m+//YZz584hMDAQgwcP\nhqurKwCgR48eePz4Maqrq7Fy5Urk5uZCKBRizpw5cHJyQmpqKi5fvozy8nLweDxYW1sjLCwMRIQN\nGzbgzJkzUFJSwuTJk2FjYwMfHx+cO3cOioqKyMzMRHx8PBISEiR02L59O44dOwYlJSVYW1vD398f\n4eHhePPmDebPn4+NGzeiV69eAID4+HgUFhZi7ty52LdvH/Ly8rB69Wrw+Xxoa2tj5cqV6NKlC6ZN\nmwYjIyNkZWWBz+cjODgYQ4cO5fLMzs5GeHg4Dh06hJqaGgwePBj79u1Dv379sHz5clhaWmLw4MEI\nCQnBn3/+iVatWuGHH37A8OHDERcXhzt37uD169eYOnUq+vfvj5CQEAD1B7KLOX78OBISEqCkpIRO\nnTohKipK4kDVefPmgYjg7u6OxMREXLhwAT///DMUFBRgamqKZcuWQV1dHZaWljA1NUVxcTEOHz4M\nZWVlLo34+Hj8/vvvEAqFGDp0KPz9/aGgoICYmBhcu3YN5eXl0NbWRlxcHPT09HD8+HFs27YNCgoK\n6NOnD1atWgUAyMrKgqenJ968eQNXV1csWLBAooxSU1Nx+vRplJeXo6SkBLa2tggMDERmZiaioqIg\nEolgYmKC5cuXS/WbR48eYfny5RAIBGjdujXWrl2Lb775hvO3srIy+Pv7o6CgAMbGxuDz+QDqZ4Qi\nIyORmZkJoVAIV1dXzJgxA9evX8eOHTvQpk0bPH36FD169MCGDRu4Q9Xd3d1x6NAhLv03b94gODgY\nlZWVKCoqgqOjI5YsWSIzrq5evYp169aBiGBgYICNGzcCAIKDg/HmzRsUFhZi4MCBnGzSZFFRUUFC\nQgIOHjwIbW1taGlpoW/fvhJxJkvvqqoqqXlFRESgsLAQ8+fPx5YtW3D06FHs2bMHIpEIpqamWLFi\nRZNDe8V5xcXF4c2bN8jLy8OrV6/g7u6Of/zjHxL3mpiYwMzMDIqKilBTU4OhoSFev36NnJwcWFpa\nol27dgAAe3t7/Pvf/4avry8OHz6M2bNnY8+ePVw69+/fh5qaGoYPH875ekVFhUx7MxgMRrN8zkPo\nGAwG42Pg8XhkampKzs7O3L+dO3cSEVFAQAAFBAQQERGfz6fx48fTq1eviIjo0qVL5OPjQ0REDg4O\ndOnSJSIiiouLI1tbW+75lJQULq/u3bsTEVFUVBTt2bOHiIgqKyvJ0dGRXr58SSkpKTRixAiqrKyk\nmpoaGj58OD169IhOnjxJnp6exOfzqaqqipydnamwsJCmTp1KV69eJSKiwMBAOnHihIRuFy5cIHd3\nd3r37h3V1dXRvHnzKDk5mYiIbG1ticfjNbGH+DqfzydbW1u6e/cuEdUfYOzq6kpERN7e3hQYGEhE\nRA8ePCBra2vuUFYiIpFIRMOHD6eKigq6ePEiWVlZUXx8PBERjRo1iioqKmjhwoWUmJhIREQvX74k\na2trKioqotjYWPL29ubScnJyovT0dCIi2rx5M2dbOzs7Ki4uJqL6g+ofPHjQRBexvR89ekSjRo2i\n0tJSIiIKCwujdevWcfdkZGQ0efbixYu0YMECEggEJBQKyc/Pj44ePUovXrwgX19fEgqFRETk7+9P\nu3btooKCArKysqLXr18TEdGSJUsoLS2NYmNjaeLEicTn86mkpIT69evX5HD3lJQUTn8+n0+TJ0+m\nU6dOUUZGBpmbm1NFRQURyfabwMBAOnnyJBERnThxgjsUV6x/eHg4RUdHExFRZmYmde/enXg8Hu3f\nv5/WrFlDRPX+7e3tTTdu3KCMjAwyMzOj169fk1AopEmTJtHZs2cl0mz4d0JCAqWmphIRUUVFBfXv\n359KSkooJSWFix8xfD6frKysuPLauHEj7d27l44fP05bt27l7hk1ahTdu3dPpixZWVk0duxYqqqq\nourqanJycqLY2Fi59JaVF4/H4/wrJyeHvLy8qLa2loiINmzYQFu2bJHpY7GxseTm5kZ8Pp+Ki4vJ\nzMyMysvLm9wv5tatW2RpaUllZWW0fft2Tk4iooMHD1JoaKjE/d7e3pyfnjhxgmbPnk1Lly4lJycn\n8vPzo7dv38rMi8FgMJqDzcAxGIwvkuaWUIpH9V+8eAEejycxql5VVYXS0lIUFxdj2LBhAOpnJ1JT\nU5vN7+rVq6itrUVKSgoAoKamBrm5uQCA/v37c4d/Gxoaory8HDdu3ICDgwNUVFSgoqLCyTpp0iQc\nO3YMZmZmyMjIQHh4uEQ+GRkZcHR0RJs2bbj7jx49iqlTp37QJi9evJCY1XBwcMDy5ctRWVkJAPDw\n8AAA9OrVC3p6enj8+DH69OkDAFBQUIC1tTWuX7+O27dvw8fHBzdu3ICtrS06duwITU1NZGRkICIi\ngtOzX79+uHv3roTNS0tLUVhYiCFDhgAAXF1dOZvZ2trCy8sLI0eOhL29PTeLKA1x3tra2gCAyZMn\nIygoiPu9X79+TZ65du0asrKyuNnT2tpaGBgYwMXFBQEBATh06BCeP3+OO3fuoHPnzvjjjz8wYMAA\ndOjQAQAQFRUFAHj48CGGDRsGFRUVtG/fHtra2igvL29ywLudnR10dXUBAOPGjUNGRgbs7e3RtWtX\naGpqApDtNyNGjMDKlStx+fJl2Nrawt7eXiLtzMxMbpZr0KBBMDQ05HR8+PAhMjIyuPQeP36Mbt26\nwcTEhNPF2Ni42T1Ws2bNQkZGBnbt2oXc3FzU1dXh3bt3Uu99/Pgx9PX1ufLy8/PjfsvKysLu3bvx\n7NkzlJWVoaamBgCkyvL8+XOMGDEC6urqAICxY8dCJBLJpbeTk5PUvMQzYED9UuK8vDzOz+vq6vDt\nt9/KtAEAWFhYQEVFBTo6OmjXrh0qKyuhpaXV5L7MzEz4+flhw4YNaNu2LUjKEboKCgoy8xEIBMjM\nzERycjL69OmDTZs2Yd26dVi3bl2z8jEYDIY02Ascg8H4r0P88iMSidCpUyfu5UkoFKK4uLjJ/qqG\nS/AUFBS4zlldXR13XSQSISoqCqampgCA4uJitG3bFsePH5dYoiV+vlUryeo1Pz8f7du3x9ixYxET\nE4NTp05h+PDhTWRp3KEF6jt/8iDtWSKCUCgEACgpKUnc21jGESNG4Nq1a8jOzsauXbvwyy+/4Pz5\n87C1teXSkpW22OYN7dc4z9DQUDx69AgXL16Ev78/fH19ZX5QorEuRCRhB3F+DREKhfDx8cF3330H\nAKioqICSkhKys7Px448/YsaMGbC3t4eioqLUMiotLeX+bvhbY52k6SYSibj/N5RNlt8oKyujf//+\nOH/+PPbs2YOLFy9yL8fS8hSnLRQK4e/vjzFjxnAyq6mp4e7du1L9UBbr1q0Dj8eDk5MTRo0ahatX\nr8q8v2F8APUfDqmurkZaWhpOnToFDw8PDBkyBDk5OVwa0mRRUFCQKNdWrVrh/fv3EmnL0jspKUlm\nXmKEQiEcHBwQGhoKAKiurub8Uxby2Oz06dMICwtDTEwMLCwsAAD6+vq4efMmd09hYSG++uormfno\n6emhS5cu3ICJk5MTFi5c2KxsDAaDIQv2FUoGg/Ffi5GREcrLy7mOVkpKCpYsWQINDQ0YGRnh7Nmz\nAOr3Zolp164dnjx5AgA4c+YMd93S0hIHDhwAUN9Zc3Z2bvarl4MGDUJaWho3szF79my8efMGqqqq\nGD58OKKjo7mZooZYWlrixIkTqK2thUAgQEpKCiwtLZvVU0lJCUKhEEZGRigrK0NWVhYA4OTJkzAw\nMOBmKU6ePAkAuHfvHioqKtC9e3eJdKytrXHlyhUoKipCQ0MDvXr1wt69e2FjY8PJdvjwYQAAj8fD\n7du3YWZmJpGGtrY2DAwMcOHCBQDgviYpEAgwZswYaGtr4/vvv4eLiwsePnwoU6fBgwfj3LlzKCsr\nAwAcPHiQ6zzLwtLSEr/++iuqq6shEAgwf/58nDp1Cjdu3MDgwYPh5eWFbt26IT09HUKhEH369MHd\nu3dRVFQEAFizZg3nE/Jw6dIlVFZWgs/n48SJE9z+psYySfObxYsXc/vsFi1aJPHBCwCwsrLiBh6y\nsrLw8uVLLr2DBw+irq4O1dXVmDJlCjcLKgslJaUmgwDp6emYNWsWHBwc8Pr1a7x580bqAAAAdO3a\nFaWlpVxcJCQk4MCBA0hPT8fkyZPh7OwMBQUFPHr0SGYaYp0uXLjA2SwtLU3qPdL0lpVXq1atON0s\nLCyQlpaGkpISEBHCwsIk9qF9DFlZWQgLC0NiYqKE/w0ZMgTXrl1DaWkp3r17h9OnT0stfzH9+/dH\naWkp98GVc+fOcS/1DAaD0VLYDByDwfivRUVFBT/99BP3UQ8NDQ2sX78eALB+/XqEhoYiLi4OxsbG\n3DNTpkzB4sWLMX78eFhaWkJPTw8A4Ovri7CwMDg5OXGzIJ07d5YYhW/I6NGjkZ2dDVdXV4hEIkyf\nPp37euS4ceNw+/ZtqcsAbW1t8fDhQ0yaNAkCgQDDhg2Dt7d3s3ra2Nhg7ty5SEhIQExMDFatWoV3\n796hbdu2iImJ4e7j8XiYOHEiACAmJkZiBgkANDQ00KFDB26WwNLSEk+ePOHkDgkJwfLly7nlphER\nEVJnHaKiohAUFIRNmzZxL3itWrXCwoUL8d1336FNmzbQ0tLiykIaPXv2xPfff49p06ahrq4Opqam\nTZabNsbOzg6PHj2Ch4cHhEIhhg0bhokTJ6KwsBC+vr4YP348lJWV0aNHD+Tn50NfXx8hISGYNWsW\nRCIRzMzM4Orqiq1btzabjxgdHR3MmTMHb9++hYuLC4YNGybx2XhAtt/MmzcPISEh2Lp1K5SUlJp8\nun/hwoUIDAyEo6MjjIyMuKWEnp6eyMvLw8SJEyEQCODq6goLC4sm+TZk5MiRcHFxkVgm/P3332Pp\n0qXQ0tKCjo4OevfuLfNz/a1bt0ZUVBSWLl2Kuro6dO7cGZGRkRIvN+rq6ujfvz/y8/PRuXNnqen0\n6tULPj4+cHNzg5aWFgwMDJrcI0tvHx8fqXkNHDgQBgYGmDZtGpKSkuDr6wsfHx+IRCL06tULc+fO\nlWkXedi2bRuEQiECAgIkZBw5ciR++OEHTJ8+HXV1dXBzc+OWEUujTZs22LJlC0JDQ/Hu3Tt06NCB\n+8AMg8FgtBQFam6NBYPBYPwPkJ+fj+nTp+PcuXN/e15CoRDR0dHQ1dXllvp9CqZNmwZfX98PzmIx\n5CM1NRWZmZlsDxODwWAwPjlsBo7BYDA+IZMmTYK2tja2bdv2uUVhMBgMBoPxBcJm4BgMBoPBYDAY\nDAbjC4F9xITBYDAYDAaDwWAwvhDYCxyDwWAwGAwGg8FgfCGwFzgGg8FgMBgMBoPB+EJgL3AMBoPB\nYDAYDAaD8YXAXuAYDAaDwWAwGAwG4wvh/wPfRhH8Jt7vewAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1141686d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot top words for both candidates to see how much each person used those words\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Initialize the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "\n",
    "# Plot the top word frequency for Trump\n",
    "sns.set_color_codes(\"pastel\")\n",
    "sns.barplot(x=\"Word\", y=\"frequency_trump\", data=top20words,\n",
    "            label=\"Trump\", color=\"b\")\n",
    "\n",
    "#Plot the top word frequency for Clinton\n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x=\"Word\", y=\"frequency_clinton\", data=top20words,\n",
    "            label=\"Clinton\", color=\"b\")\n",
    "\n",
    "# Add a legend and informative axis label\n",
    "ax.legend(ncol=2, loc=\"upper right\", frameon=True)\n",
    "ax.set(xlim=(0, 30), ylabel=\"\",\n",
    "       xlabel=\"Frequency of top words for each presidential candidate in 2016\")\n",
    "sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top words used by each candidate (along with visuals for valence of those words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>ValMn</th>\n",
       "      <th>AroMn</th>\n",
       "      <th>DomMn</th>\n",
       "      <th>frequency_trump</th>\n",
       "      <th>frequency_clinton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>country</td>\n",
       "      <td>5.93</td>\n",
       "      <td>5.26</td>\n",
       "      <td>5.96</td>\n",
       "      <td>1848.0</td>\n",
       "      <td>338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>know</td>\n",
       "      <td>6.93</td>\n",
       "      <td>5.77</td>\n",
       "      <td>6.90</td>\n",
       "      <td>2284.0</td>\n",
       "      <td>622.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>like</td>\n",
       "      <td>7.52</td>\n",
       "      <td>6.63</td>\n",
       "      <td>5.41</td>\n",
       "      <td>1344.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>people</td>\n",
       "      <td>7.33</td>\n",
       "      <td>5.94</td>\n",
       "      <td>6.14</td>\n",
       "      <td>3155.0</td>\n",
       "      <td>669.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>president</td>\n",
       "      <td>5.20</td>\n",
       "      <td>5.63</td>\n",
       "      <td>4.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>334.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>right</td>\n",
       "      <td>6.45</td>\n",
       "      <td>4.79</td>\n",
       "      <td>6.38</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>think</td>\n",
       "      <td>6.41</td>\n",
       "      <td>5.34</td>\n",
       "      <td>6.38</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>297.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>want</td>\n",
       "      <td>5.25</td>\n",
       "      <td>6.00</td>\n",
       "      <td>4.54</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>491.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>work</td>\n",
       "      <td>3.96</td>\n",
       "      <td>5.11</td>\n",
       "      <td>4.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>341.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>going</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5186.0</td>\n",
       "      <td>553.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dont</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1772.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>great</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1729.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>said</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1586.0</td>\n",
       "      <td>293.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>one</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1504.0</td>\n",
       "      <td>272.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>theyre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1462.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hillary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>get</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1381.0</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>thats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>272.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>jobs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1253.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>im</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1160.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>clinton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1142.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>say</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>america</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>make</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>379.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>trump</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>us</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>314.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>got</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>283.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>together</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>donald</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>well</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Word  ValMn  AroMn  DomMn  frequency_trump  frequency_clinton\n",
       "0     country   5.93   5.26   5.96           1848.0              338.0\n",
       "1        know   6.93   5.77   6.90           2284.0              622.0\n",
       "2        like   7.52   6.63   5.41           1344.0                NaN\n",
       "3      people   7.33   5.94   6.14           3155.0              669.0\n",
       "4   president   5.20   5.63   4.77              NaN              334.0\n",
       "5       right   6.45   4.79   6.38           1515.0                NaN\n",
       "6       think   6.41   5.34   6.38           1070.0              297.0\n",
       "7        want   5.25   6.00   4.54           1360.0              491.0\n",
       "8        work   3.96   5.11   4.11              NaN              341.0\n",
       "9       going    NaN    NaN    NaN           5186.0              553.0\n",
       "10       dont    NaN    NaN    NaN           1772.0                NaN\n",
       "11      great    NaN    NaN    NaN           1729.0                NaN\n",
       "12       said    NaN    NaN    NaN           1586.0              293.0\n",
       "13        one    NaN    NaN    NaN           1504.0              272.0\n",
       "14     theyre    NaN    NaN    NaN           1462.0                NaN\n",
       "15    hillary    NaN    NaN    NaN           1460.0                NaN\n",
       "16        get    NaN    NaN    NaN           1381.0              398.0\n",
       "17      thats    NaN    NaN    NaN           1265.0              272.0\n",
       "18       jobs    NaN    NaN    NaN           1253.0                NaN\n",
       "19         im    NaN    NaN    NaN           1160.0                NaN\n",
       "20    clinton    NaN    NaN    NaN           1142.0                NaN\n",
       "21        say    NaN    NaN    NaN           1070.0                NaN\n",
       "22    america    NaN    NaN    NaN              NaN              388.0\n",
       "23       make    NaN    NaN    NaN              NaN              379.0\n",
       "24      trump    NaN    NaN    NaN              NaN              335.0\n",
       "25         us    NaN    NaN    NaN              NaN              314.0\n",
       "26        got    NaN    NaN    NaN              NaN              283.0\n",
       "27   together    NaN    NaN    NaN              NaN              257.0\n",
       "28     donald    NaN    NaN    NaN              NaN              256.0\n",
       "29       well    NaN    NaN    NaN              NaN              255.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#most frequently used words for each candidate along with valence\n",
    "#make a new dataframe that includes valence values along with top20words \n",
    "top20valence = pd.merge(anew_sliced, top20words, on='Word', how='right')\n",
    "top20valence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: many of the top 20 words for each candidate don't appear in ANEW. This issue is addressed in another section of our analyses below aptly titled \"Words NOT Captured by ANEW\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a graph of the most frequently used words for each candidate, and how many times each of them used it. You can hover over the nodes to display the actual words.\n",
    "\n",
    "Something that stood out to me as interesting was which words were exclusive to each of the candidates (appear along the axes). For instance, although Trump was all about boosting employment and reinvigorating the coal mining industry, it was actually Hillary who used the word \"work\" the most. Trump's unique most frequently used word was \"right\"--which also seemingly speaks volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~peachypunk/40.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "plotly.tools.set_credentials_file(username='peachypunk', api_key='zl14cGCYwyddRaQklh90')\n",
    "\n",
    "\n",
    "data = [\n",
    "    go.Scatter(\n",
    "        x= top20valence.frequency_trump,\n",
    "        y=top20valence.frequency_clinton,\n",
    "        mode='markers',\n",
    "        text=top20valence.Word\n",
    "    )\n",
    "]\n",
    "layout = go.Layout(\n",
    "    title='Words Most Frequently Used By Each Candidate',\n",
    "    xaxis = dict(\n",
    "        title='Trump Frequency'),\n",
    "    yaxis = dict(\n",
    "        title= 'Clinton Frequency'))\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an even cooler version of the graph from above. This visualization incorporates the ratings or sentiment scores for each word by coloring the nodes according to their valence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~peachypunk/42.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "    go.Scatter(\n",
    "        x= top20valence.frequency_trump,\n",
    "        y=top20valence.frequency_clinton,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "        size='16',\n",
    "        color = top20valence.ValMn, #set color equal to a variable\n",
    "        colorscale='YlOrRd',\n",
    "        showscale=True\n",
    "    ),\n",
    "        text=top20valence.Word\n",
    "    )\n",
    "]\n",
    "layout = go.Layout(\n",
    "    title='Words Most Frequently Used By Each Candidate',\n",
    "    xaxis = dict(\n",
    "        title='Trump Frequency'),\n",
    "    yaxis = dict(\n",
    "        title= 'Clinton Frequency'))\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexical Factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something else we were interested in examining is the common text analysis measure of lexical diversity. Lexical richness or lexical diversity reflects the number of distinct words used by each candidate: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clinton 0.11153259764774212\n",
      "Trump 0.041923533934437686\n"
     ]
    }
   ],
   "source": [
    "print('Clinton', len(set(clean_clinton)) / len(clean_clinton))\n",
    "print('Trump', len(set(clean_trump)) / len(clean_trump))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that Clinton's speeches contained a more diverse set of words overall compared to Trump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 'We're Hip and With It': Or How I Learned to Target the Youth\n",
    "\n",
    "Something else we were interested in examining was the prevalence of social media and related terms used by each candidate. We anticipated that incorporating this language served two purposes: it allowed the candidates to seem up to date with tech and culture, and more importantly it allowed them to reach out to the base of young voters that both Trump and Clinton were interested in recruiting. \n",
    "\n",
    "We expected that Hillary was aiming to recruit the youth more actively. This was particularly reflected by the use of memes in her campaign, her appearances on shows popular with twenty-somethings (i.e. Broad City), and maintaining a carefully pruned image on various social media platforms. \n",
    "\n",
    "However, it's also important to consider that Trump is a yuuuuuge Tweeter, and he was heavily embroiled in the blame game re:Hillary's emails at the time. So if he seemed to use more social media terms, I wouldn't exactly be surprised. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'online': 11, 'emails': 8, 'tweet': 7, 'twitter': 4, 'email': 4, 'facebook': 2, 'google': 1})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    0.067156\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count how often a word occurs in a text, and compute what percentage of the text is taken \n",
    "#up by a specific word. \n",
    "#we can do this for social media words (i.e. Facebook, tweet, Twitter, social media, online)\n",
    "\n",
    "from collections import Counter\n",
    "social_media_counts_clinton = Counter()\n",
    "words = ('facebook', 'tweet', 'twitter', 'social media', 'online', 'email', 'emails', 'blog', 'google', 'hashtag', 'selfie', 'viral')\n",
    "for word in clean_clinton:\n",
    "    if word in words:\n",
    "        social_media_counts_clinton[word] += 1\n",
    "print (social_media_counts_clinton)\n",
    "\n",
    "#compute the percentage of their speech text that consists of words related to social media \n",
    "social_media_counts_clinton = pd.DataFrame(social_media_counts_clinton, index=['count'])\n",
    "social_media_sum_clinton = social_media_counts_clinton.sum(axis =1)\n",
    "percent_soc_media_clinton = 100 * (social_media_sum_clinton / len(clean_clinton))\n",
    "percent_soc_media_clinton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'emails': 266, 'email': 45, 'online': 14, 'twitter': 8, 'facebook': 7, 'tweet': 3})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    0.159829\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "social_media_counts_trump = Counter()\n",
    "words = ('facebook', 'tweet', 'twitter', 'social media', 'online', 'email', 'emails', 'blog', 'google', 'hashtag', 'selfie', 'viral')\n",
    "for word in clean_trump:\n",
    "    if word in words:\n",
    "        social_media_counts_trump[word] += 1\n",
    "print (social_media_counts_trump)\n",
    "\n",
    "#compute the percentage of their speech text that consists of words related to social media \n",
    "social_media_counts_trump = pd.DataFrame(social_media_counts_trump, index=['count'])\n",
    "social_media_sum_trump = social_media_counts_trump.sum(axis =1)\n",
    "percent_soc_media_trump = 100 * (social_media_sum_trump / len(clean_trump))\n",
    "percent_soc_media_trump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that .32% of Trump's speeches consisted of words related to social media/tech, whereas Clinton's speeches consisted of only .13%. \n",
    "\n",
    "This difference between candidates seems to provide further evidence of the role of the email scandal and how predominantly it was featured as a rhetorical tactic in his speeches. Clinton may have intentionally avoided using certain terms (i.e. \"email\") in order to not bring further attention to a topic that was bringing her negative press at the time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Words NOT captured by ANEW\n",
    "After getting the weighted sums, we were curious about the words in the two corpora that were NOT in the ANEW list. Perhaps those words can give us better insight into the \"affectiveness\" of each presidential candidate's speeches.\n",
    "\n",
    "To explore that question, we'll filter out the ANEW words from each corpus and examine the remaining words.\n",
    "\n",
    "This is a function that filters out the ANEW words from the corpora.\n",
    "The function will prune a text input by excluding a set of words. It takes \"text_input\" as the input. In the input, it'll exclude words that are in \"words_to_exclude\". It returns a list of words called \"pruned_list\", which contains the leftover words that WEREN'T in the \"words_to_exclude\" list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def excludewords(text_input, words_to_exclude):\n",
    "    pruned_list = []\n",
    "    for w in text_input:\n",
    "        if w not in words_to_exclude:\n",
    "            pruned_list.append(w)\n",
    "    return pruned_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll apply excludewords() on the cleaned trump corpus and clinton corpus, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trump_pruned = excludewords(clean_trump, wordlist)\n",
    "clinton_pruned = excludewords(clean_clinton, wordlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many words weren't captured by ANEW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165384\n",
      "41943\n"
     ]
    }
   ],
   "source": [
    "print(len(trump_pruned))\n",
    "print(len(clinton_pruned))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are 37453 words in Trump corpus and 11670 words in Clinton corpus that were NOT in the ANEW list. Many of these words seem to have high valence, so we planned to do additional sentiment analyses on these words. However, we didn't have enough time to perform this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Considerations and Next Steps\n",
    "\n",
    "Some other ideas we talked about implementing for this project but didn't get time to include are: \n",
    "\n",
    "-a \"how presidential\" function. This function would run through the corpus of all presidential inaugural speeches to establish which terms are common across all the presidents to develop an index of \"presidential speech\", so to speak (pun not intended). \n",
    "\n",
    "This corpus of presidential speech would then be used as a comparative point for the speeches delivered by both presidential candidate. In other words, how many of those presidential words did Clinton and Trump employ in their own speeches? This function could be fun to use in other ways too, including speeches delivered by fake presidents on TV shows and in films. \n",
    "\n",
    "We could also pull popularity ratings for each president over time and include that determine what emotional valence qualities were associated with the most popular presidents. For example, JFK was very well liked. Was he more emotional in his speeches? Was Clinton? \n",
    "\n",
    "We could then plot each candidate’s location on the presidential language curve in a graph as well. \n",
    "\n",
    "-we could also consider coming up with our own list of custom stopwords to exclude since some of the ones included in the NLTK set seemed to actually be relevant to our analysis. \n",
    "\n",
    "-something we tried to achieve, but ran out of time to work on was reclassifying the words that were not captured by ANEW\n",
    "    We could either reclassify the words ourselves manually, or use unsupervised machine learning to first group them and then apply our own valence grades\n",
    "    \n",
    "-find words similar to the tagged words in ANEW as a way to expand the ANEW corpus and getting word counts for those “similar words” too (perhaps using Wikipedia lists that Drew linked us to or Wordnet)\n",
    "\n",
    "-we were also interested in doing a separate analysis of exaggeration words, positive qualifiers, and adjectives\n",
    "\n",
    "-visualize the text as a network by making a scatterplot that shows co-occurring words using concordance\n",
    "\n",
    "-find entire sets of words that only occurred once in each corpus (aka hapaxes)\n",
    "\n",
    "-decipher important measures to each person (i.e. social media presence, china, wall, obamacare, etc.)\n",
    "\n",
    "-We wanted to collect information about \"microvalences\" within the text. Valence scores surrounding certain words in the text like the opponent's name, or a certain issue in the debates. It would also be interesting to look at this information across time in one or even multiple debates or speeches.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Print Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The printtext() function is a simple function that outputs a corpus or tokenizer variable to a textfile in the current filepath. It's sometimes handy if you'd like to see/check what the cleaned corpus looks like after you run it through the text cleaning.\n",
    "\n",
    "It takes two arguments- the name of the corpus variable to export, and the title of the file that you would like to enter in a string format- 'example_name'.\n",
    "\n",
    "example:\n",
    "printtext(text to export, 'name of txt file')\n",
    "exporttext(clean_trump, 'testexport')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def exporttext(text2print, file_title):\n",
    "    \n",
    "    #export clean_trump to text file\n",
    "    file_t = file_title\n",
    "    trump_print = ' '.join(text2print)\n",
    "    file = open(file_t + '.txt','w') \n",
    "    file.write(str(trump_print)) \n",
    "    file.close() \n",
    "    return \"Text exported to enclosing directory!\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus Citations##\n",
    "\n",
    "Brown, D. W. (2017) Clinton-Trump Corpus. Retrieved from http://www.thegrammarlab.com\n",
    "\n",
    "Brown, D. W. (2016) Corpus of Presidential Speeches. Retrieved from http://www.thegrammarlab.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANEW Citation\n",
    "Bradley, M.M., & Lang, P.J. (1999). Affective norms for English words (ANEW): Stimuli, instruction manual and affective ratings. Technical report C-1, Gainesville, FL. The Center for Research in Psychophysiology, University of Florida."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
